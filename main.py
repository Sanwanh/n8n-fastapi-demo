#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸‚å ´åˆ†æå ±å‘Šç³»çµ± - APIæœå‹™ (ä¿®æ­£ç‰ˆ)
ä¸»è¦ä¿®æ­£ï¼š
1. ä¿®æ­£å¸‚å ´æ•¸æ“šé¡¯ç¤ºå•é¡Œ
2. å¢å¼·éŒ¯èª¤è™•ç†å’Œæ—¥èªŒ
3. ç¢ºä¿æ•¸æ“šæ­£ç¢ºå‚³éåˆ°å‰ç«¯
"""

import os
import sys
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional, Any
import asyncio

# ç¬¬ä¸‰æ–¹å¥—ä»¶
try:
    from fastapi import FastAPI, Request, HTTPException
    from fastapi.responses import JSONResponse, HTMLResponse
    from fastapi.staticfiles import StaticFiles
    from fastapi.middleware.cors import CORSMiddleware
    from pydantic import BaseModel, EmailStr, validator
    import uvicorn
    import requests
    import yfinance as yf
    import pandas as pd
    import numpy as np
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„å¥—ä»¶: {e}")
    print("è«‹åŸ·è¡Œ: pip install -r requirements.txt")
    sys.exit(1)

# è¨­å®šæ—¥èªŒ - å¢å¼·ç‰ˆæœ¬
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('logs/market_analysis.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
Path("logs").mkdir(exist_ok=True)
Path("data").mkdir(exist_ok=True)
Path("frontend/static").mkdir(parents=True, exist_ok=True)


# è¼‰å…¥é…ç½®
def load_config():
    return {
        'SERVER_CONFIG': {
            'host': os.getenv('SERVER_HOST', '0.0.0.0'),
            'port': int(os.getenv('SERVER_PORT', 8089)),
            'debug': os.getenv('DEBUG', 'False').lower() == 'true'
        },
        'WEBHOOK_CONFIG': {
            'send_url': os.getenv(
                'WEBHOOK_URL',
                'https://beloved-swine-sensibly.ngrok-free.app/webhook-test/ef5ac185-f41a-4a2d-9a78-33d329184c2'
            ),
            'n8n_webhook_url': 'https://beloved-swine-sensibly.ngrok-free.app/webhook/Webhook - Preview',
            'timeout': int(os.getenv('WEBHOOK_TIMEOUT', 30))
        },
        'SYSTEM_INFO': {
            'name': 'Market Analysis API',
            'version': '2.1.2',
            'description': 'æ™ºèƒ½å¸‚å ´åˆ†æAPIæœå‹™ - ä¿®æ­£ç‰ˆ'
        }
    }


CONFIG = load_config()


# è³‡æ–™æ¨¡å‹
class N8NDataExtended(BaseModel):
    average_sentiment_score: float
    message_content: str
    market_date: Optional[str] = None
    confidence_level: Optional[str] = None
    trend_direction: Optional[str] = None
    risk_assessment: Optional[str] = None

    @validator('average_sentiment_score')
    def validate_sentiment_score(cls, v):
        if not -1.0 <= v <= 1.0:
            raise ValueError('æƒ…æ„Ÿåˆ†æ•¸å¿…é ˆåœ¨ -1.0 åˆ° 1.0 ä¹‹é–“')
        return v


class MailSenderRequest(BaseModel):
    recipient_email: EmailStr
    sender_name: Optional[str] = "å¸‚å ´åˆ†æç³»çµ±"
    subject: Optional[str] = "å¸‚å ´åˆ†æå ±å‘Š"
    priority: Optional[str] = "normal"
    mail_type: Optional[str] = "daily"
    custom_message: Optional[str] = ""
    include_charts: bool = False
    include_recommendations: bool = False
    include_risk_warning: bool = False


# åˆå§‹åŒ– FastAPI
app = FastAPI(
    title=CONFIG['SYSTEM_INFO']['name'],
    description=CONFIG['SYSTEM_INFO']['description'],
    version=CONFIG['SYSTEM_INFO']['version'],
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ›è¼‰éœæ…‹æª”æ¡ˆ
app.mount("/static", StaticFiles(directory="frontend/static"), name="static")


# Web è·¯ç”±
@app.get("/", response_class=HTMLResponse)
async def home():
    """ä¸»é é¢ - é¡¯ç¤ºå¸‚å ´æ•¸æ“šå’Œé»ƒé‡‘åƒ¹æ ¼"""
    html_file = Path("frontend") / "index.html"
    if html_file.exists():
        with open(html_file, 'r', encoding='utf-8') as f:
            return HTMLResponse(content=f.read())
    return HTMLResponse(content="<h1>é¦–é æª”æ¡ˆä¸å­˜åœ¨</h1>", status_code=404)


@app.get("/mail", response_class=HTMLResponse)
async def mail_page():
    """éƒµä»¶ç™¼é€é é¢"""
    html_file = Path("frontend") / "mail.html"
    if html_file.exists():
        with open(html_file, 'r', encoding='utf-8') as f:
            return HTMLResponse(content=f.read())
    return HTMLResponse(content="<h1>éƒµä»¶é é¢æª”æ¡ˆä¸å­˜åœ¨</h1>", status_code=404)


# å…¨åŸŸè®Šæ•¸ - å¢å¼·ç‰ˆæœ¬
stored_data = {}
system_stats = {
    "total_reports": 0,
    "today_reports": 0,
    "last_reset": datetime.now().date(),
    "uptime_start": datetime.now(),
    "last_data_received": None,
    "api_calls": 0,
    "gold_price_calls": 0,
    "errors": 0
}


# API è·¯ç”±
@app.post("/api/n8n-data")
async def receive_n8n_data(request: Request):
    """æ¥æ”¶ä¾†è‡ª N8N çš„å¸‚å ´åˆ†æè³‡æ–™ - å¢å¼·ç‰ˆæœ¬"""
    try:
        global stored_data, system_stats

        raw_data = await request.json()
        logger.info(f"ğŸ“¨ æ”¶åˆ° N8N åŸå§‹è³‡æ–™å¤§å°: {len(json.dumps(raw_data, ensure_ascii=False))} å­—å…ƒ")
        logger.info(f"ğŸ“¨ æ”¶åˆ° N8N è³‡æ–™: {json.dumps(raw_data, ensure_ascii=False)[:500]}...")

        # å¢å¼·çš„æ•¸æ“šè™•ç†é‚è¼¯
        if isinstance(raw_data, list) and len(raw_data) > 0:
            market_data = raw_data[0]
            logger.info("âœ… è™•ç†é™£åˆ—æ ¼å¼æ•¸æ“šï¼Œå–ç¬¬ä¸€å€‹å…ƒç´ ")
        elif isinstance(raw_data, dict):
            market_data = raw_data
            logger.info("âœ… è™•ç†å­—å…¸æ ¼å¼æ•¸æ“š")
        else:
            logger.error(f"âŒ ç„¡æ•ˆçš„è³‡æ–™æ ¼å¼: {type(raw_data)}")
            raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„è³‡æ–™æ ¼å¼: {type(raw_data)}")

        # è©³ç´°è¨˜éŒ„æ¥æ”¶åˆ°çš„æ•¸æ“šæ¬„ä½
        logger.info(f"ğŸ“Š æ•¸æ“šæ¬„ä½: {list(market_data.keys())}")

        # æ§‹å»ºå„²å­˜çš„æ•¸æ“š
        current_time = datetime.now()
        stored_data = {
            "average_sentiment_score": float(market_data.get("average_sentiment_score", 0)),
            "message_content": str(market_data.get("message_content", "")),
            "market_date": str(market_data.get("market_date", current_time.strftime("%Yå¹´%mæœˆ%dæ—¥"))),
            "confidence_level": str(market_data.get("confidence_level", "æœªçŸ¥")),
            "trend_direction": str(market_data.get("trend_direction", "æœªçŸ¥")),
            "risk_assessment": str(market_data.get("risk_assessment", "æœªçŸ¥")),
            "received_time": current_time.strftime("%Y-%m-%d %H:%M:%S"),
            "received_timestamp": current_time.isoformat(),
            "raw_data": market_data,
            "data_source": "N8N Webhook",
            "processing_time": datetime.now().isoformat()
        }

        # æ›´æ–°ç³»çµ±çµ±è¨ˆ
        system_stats["total_reports"] += 1
        system_stats["today_reports"] += 1
        system_stats["last_data_received"] = current_time.isoformat()

        # è©³ç´°è¨˜éŒ„è™•ç†å¾Œçš„æ•¸æ“š
        # logger.info(f"âœ… æˆåŠŸè™•ç† N8N è³‡æ–™:")
        # logger.info(f"   æƒ…æ„Ÿåˆ†æ•¸: {stored_data['average_sentiment_score']}")
        # logger.info(f"   å…§å®¹é•·åº¦: {len(stored_data['message_content'])} å­—å…ƒ")
        # logger.info(f"   å¸‚å ´æ—¥æœŸ: {stored_data['market_date']}")
        # logger.info(f"   ä¿¡å¿ƒæ°´å¹³: {stored_data['confidence_level']}")
        # logger.info(f"   è¶¨å‹¢æ–¹å‘: {stored_data['trend_direction']}")
        # logger.info(f"   é¢¨éšªè©•ä¼°: {stored_data['risk_assessment']}")
        # logger.info(f"   æ¥æ”¶æ™‚é–“: {stored_data['received_time']}")

        return {
            "status": "success",
            "message": "å¸‚å ´åˆ†æè³‡æ–™å·²æ¥æ”¶ä¸¦å„²å­˜",
            "data": stored_data,
            "received_at": current_time.isoformat(),
            "processed_fields": len(stored_data),
            "system_stats": system_stats
        }

    except ValueError as ve:
        logger.error(f"âŒ æ•¸æ“šé©—è­‰éŒ¯èª¤: {str(ve)}")
        system_stats["errors"] += 1
        raise HTTPException(status_code=400, detail=f"æ•¸æ“šé©—è­‰éŒ¯èª¤: {str(ve)}")
    except Exception as e:
        logger.error(f"âŒ æ¥æ”¶ N8N è³‡æ–™å¤±æ•—: {str(e)}")
        system_stats["errors"] += 1
        raise HTTPException(status_code=500, detail=f"æ¥æ”¶è³‡æ–™å¤±æ•—: {str(e)}")


@app.get("/api/current-data")
async def get_current_data():
    """å–å¾—ç›®å‰å„²å­˜çš„å¸‚å ´åˆ†æè³‡æ–™ - å¢å¼·ç‰ˆæœ¬"""
    try:
        system_stats["api_calls"] += 1

        logger.info(f"ğŸ“¤ API è«‹æ±‚ /api/current-data")
        logger.info(f"ğŸ“Š ç•¶å‰å„²å­˜æ•¸æ“šç‹€æ…‹: {'æœ‰æ•¸æ“š' if stored_data else 'ç„¡æ•¸æ“š'}")

        if stored_data:
            logger.info(f"ğŸ“Š æ•¸æ“šè©³æƒ…:")
            logger.info(f"   æƒ…æ„Ÿåˆ†æ•¸: {stored_data.get('average_sentiment_score', 'N/A')}")
            logger.info(f"   å…§å®¹é•·åº¦: {len(stored_data.get('message_content', ''))} å­—å…ƒ")
            logger.info(f"   æ¥æ”¶æ™‚é–“: {stored_data.get('received_time', 'N/A')}")

        # æª¢æŸ¥æ•¸æ“šæ˜¯å¦éæœŸï¼ˆè¶…é1å°æ™‚ï¼‰
        data_age_minutes = 0
        if stored_data and stored_data.get('received_timestamp'):
            try:
                received_time = datetime.fromisoformat(stored_data['received_timestamp'])
                data_age_minutes = (datetime.now() - received_time).total_seconds() / 60
                logger.info(f"ğŸ“… æ•¸æ“šå¹´é½¡: {data_age_minutes:.1f} åˆ†é˜")
            except Exception as e:
                logger.warning(f"âš ï¸ ç„¡æ³•è¨ˆç®—æ•¸æ“šå¹´é½¡: {e}")

        response_data = {
            "status": "success",
            "data": stored_data,
            "stats": system_stats,
            "timestamp": datetime.now().isoformat(),
            "has_data": len(stored_data) > 0,
            "data_age_minutes": data_age_minutes,
            "data_freshness": "fresh" if data_age_minutes < 60 else "stale" if data_age_minutes < 1440 else "very_old"
        }

        logger.info(f"âœ… å›å‚³æ•¸æ“š: {len(stored_data)} å€‹æ¬„ä½")
        return response_data

    except Exception as e:
        logger.error(f"âŒ å–å¾—ç•¶å‰æ•¸æ“šå¤±æ•—: {str(e)}")
        system_stats["errors"] += 1
        raise HTTPException(status_code=500, detail=f"å–å¾—æ•¸æ“šå¤±æ•—: {str(e)}")


@app.get("/api/gold-price")
async def get_gold_price(period: str = "1y", interval: str = "1d"):
    """å–å¾—é»ƒé‡‘æœŸè²¨åƒ¹æ ¼ - å¢å¼·ç‰ˆæœ¬"""
    try:
        system_stats["gold_price_calls"] += 1

        # é©—è­‰åƒæ•¸
        valid_periods = ["1d", "5d", "1mo", "3mo", "6mo", "1y", "2y", "5y"]
        valid_intervals = ["1m", "5m", "15m", "30m", "1h", "1d"]

        if period not in valid_periods:
            logger.warning(f"ç„¡æ•ˆçš„æ™‚é–“æœŸé–“: {period}ï¼Œä½¿ç”¨é è¨­å€¼ 1y")
            period = "1y"

        if interval not in valid_intervals:
            logger.warning(f"ç„¡æ•ˆçš„æ™‚é–“é–“éš”: {interval}ï¼Œä½¿ç”¨é è¨­å€¼ 1d")
            interval = "1d"

        logger.info(f"ğŸ” é–‹å§‹ç²å–é»ƒé‡‘æœŸè²¨æ•¸æ“š")
        logger.info(f"   æœŸé–“: {period}")
        logger.info(f"   é–“éš”: {interval}")
        logger.info(f"   è«‹æ±‚æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # ç²å–é»ƒé‡‘æœŸè²¨æ•¸æ“š
        try:
            hist_data, info, current_price, latest_processing_time = await get_gold_futures_data_enhanced(period, interval)

            if hist_data is None or hist_data.empty:
                logger.warning("âš ï¸ ä¸»è¦æ•¸æ“šæºç„¡æ•¸æ“šï¼Œä½¿ç”¨å‚™é¸æ–¹æ¡ˆ...")
                return create_mock_gold_data(period)

        except Exception as e:
            logger.error(f"âŒ yfinance æ•¸æ“šç²å–å¤±æ•—: {str(e)}")
            return create_mock_gold_data(period)

        logger.info(f"âœ… æˆåŠŸç²å–é»ƒé‡‘æ•¸æ“š:")
        logger.info(f"   æ•¸æ“šé»æ•¸é‡: {len(hist_data)}")
        logger.info(
            f"   æ—¥æœŸç¯„åœ: {hist_data.index[0].strftime('%Y-%m-%d')} åˆ° {hist_data.index[-1].strftime('%Y-%m-%d')}")

        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        stats = calculate_gold_statistics(hist_data)

        if not stats:
            logger.warning("âš ï¸ çµ±è¨ˆè¨ˆç®—å¤±æ•—ï¼Œä½¿ç”¨å‚™é¸æ•¸æ“š")
            return create_mock_gold_data(period)

        # logger.info(f"ğŸ’° åƒ¹æ ¼çµ±è¨ˆ:")
        # logger.info(f"   ç•¶å‰åƒ¹æ ¼: ${stats['current_price']:.2f}")
        # logger.info(f"   åƒ¹æ ¼è®ŠåŒ–: ${stats['price_change']:+.2f} ({stats['price_change_pct']:+.2f}%)")
        # logger.info(f"   åƒ¹æ ¼ç¯„åœ: ${stats['min_price']:.2f} - ${stats['max_price']:.2f}")
        # logger.info(f"   å¹³å‡åƒ¹æ ¼: ${stats['avg_price']:.2f}")
        # logger.info(f"   æ³¢å‹•ç‡: {stats['volatility']:.2f}")

        # æº–å‚™åœ–è¡¨æ•¸æ“š
        chart_data = []
        for idx, row in hist_data.iterrows():
            try:
                # ä¿®æ­£æ™‚å€å•é¡Œï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                if hasattr(idx, 'tz_localize'):
                    if idx.tz is None:
                        # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        idx_local = idx + timedelta(hours=8)
                    else:
                        # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        idx_local = idx.tz_convert('Asia/Taipei')
                else:
                    # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    idx_local = idx + timedelta(hours=8)
                
                data_point = {
                    "time": idx_local.strftime('%Y-%m-%d'),
                    "price": float(row['Close']) if not pd.isna(row['Close']) else stats['current_price'],
                    "high": float(row['High']) if not pd.isna(row['High']) else stats['current_price'],
                    "low": float(row['Low']) if not pd.isna(row['Low']) else stats['current_price'],
                    "open": float(row['Open']) if not pd.isna(row['Open']) else stats['current_price'],
                    "volume": int(row['Volume']) if not pd.isna(row['Volume']) and row['Volume'] > 0 else 0
                }
                logger.debug(f"æ•¸æ“šé»: {data_point['time']} - ${data_point['price']:.2f}")
                chart_data.append(data_point)
            except Exception as point_error:
                logger.warning(f"âš ï¸ è™•ç†æ•¸æ“šé»æ™‚å‡ºéŒ¯: {point_error}")
                continue

        # logger.info(f"ğŸ“Š åœ–è¡¨æ•¸æ“š:")
        # logger.info(f"   æœ‰æ•ˆæ•¸æ“šé»: {len(chart_data)}")
        if chart_data:
            prices = [d['price'] for d in chart_data]
            valid_prices = [p for p in prices if not pd.isna(p) and p > 0]
            logger.info(f"   æœ‰æ•ˆåƒ¹æ ¼æ•¸é‡: {len(valid_prices)}")
            if valid_prices:
                logger.info(f"   åƒ¹æ ¼ç¯„åœ: ${min(valid_prices):.2f} - ${max(valid_prices):.2f}")
            # logger.info(f"   å‰3å€‹æ•¸æ“šé»: {chart_data[:3]}")

        # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
        technical_indicators = calculate_technical_indicators_enhanced(hist_data)
        logger.info(f"ğŸ“ˆ æŠ€è¡“æŒ‡æ¨™: {list(technical_indicators.keys())}")

        # åˆ¤æ–·å¸‚å ´ç‹€æ…‹
        market_status = determine_market_status()
        logger.info(f"ğŸª å¸‚å ´ç‹€æ…‹: {market_status}")

        # ç²å–å¸‚å ´è³‡è¨Š
        market_name = get_market_name(info)

        # æº–å‚™å›æ‡‰æ•¸æ“š
        response_data = {
            "status": "success",
            "data": {
                "symbol": "GC=F",
                "name": market_name,
                "current_price": round(stats['current_price'], 2),
                "change": round(stats['price_change'], 2),
                "change_percent": round(stats['price_change_pct'], 2),
                "high_24h": round(stats['max_price'], 2),
                "low_24h": round(stats['min_price'], 2),
                "avg_price": round(stats['avg_price'], 2),
                "volatility": round(stats['volatility'], 2),
                "volume_24h": int(hist_data['Volume'].sum()) if not hist_data['Volume'].isna().all() else 0,
                "currency": "USD",
                "unit": "per ounce",
                "last_updated": stats['latest_date'].isoformat(),
                "last_updated_formatted": latest_processing_time,
                "chart_data": chart_data,
                "market_status": market_status,
                "technical_indicators": technical_indicators,
                "period": period,
                "interval": interval,
                "data_points": len(chart_data),
                "trading_days": len(hist_data),
                "data_source_info": {
                    "primary": "Yahoo Finance",
                    "realtime_updated": len(chart_data) > 0 and
                                        chart_data[-1]['time'].split('T')[0] == datetime.now().strftime('%Y-%m-%d')
                }
            },
            "system_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "next_update": (datetime.now() + timedelta(minutes=5)).strftime("%Y-%m-%d %H:%M:%S"),
            "data_source": "Yahoo Finance API (Enhanced)",
            "processing_stats": {
                "raw_data_points": len(hist_data),
                "processed_chart_points": len(chart_data),
                "technical_indicators_count": len(technical_indicators),
                "processing_time": datetime.now().isoformat()
            }
        }

        logger.info(f"âœ… æˆåŠŸå›å‚³é»ƒé‡‘åƒ¹æ ¼æ•¸æ“š:")
        logger.info(f"   å›æ‡‰å¤§å°: {len(json.dumps(response_data))} å­—å…ƒ")
        logger.info(f"   åœ–è¡¨æ•¸æ“šé»: {len(chart_data)}")

        return response_data

    except Exception as e:
        logger.error(f"âŒ ç²å–é»ƒé‡‘åƒ¹æ ¼å¤±æ•—: {str(e)}")
        system_stats["errors"] += 1
        return create_mock_gold_data(period)


async def get_gold_futures_data_enhanced(period: str, interval: str):
    """ç²å–é»ƒé‡‘æœŸè²¨æ•¸æ“š - å¢å¼·ç‰ˆæœ¬"""
    try:
        # è¨ˆç®—æ™‚é–“ç¯„åœ
        period_days_map = {
            '1d': 1, '5d': 5, '1mo': 30, '3mo': 90,
            '6mo': 180, '1y': 365, '2y': 730, '5y': 1825
        }
        period_days = period_days_map.get(period, 365)

        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)

        logger.info(f"ğŸ• æ™‚é–“ç¯„åœ: {start_date.strftime('%Y-%m-%d')} è‡³ {end_date.strftime('%Y-%m-%d')}")

        # ä½¿ç”¨yfinanceç²å–æ•¸æ“š
        gold_ticker = yf.Ticker("GC=F")

        # ç²å–æ­·å²æ•¸æ“š
        logger.info(f"ğŸ“Š æ­£åœ¨ç²å–æ­·å²æ•¸æ“š...")
        hist_data = gold_ticker.history(
            start=start_date.strftime('%Y-%m-%d'),
            end=end_date.strftime('%Y-%m-%d'),
            interval=interval
        )

        logger.info(f"ğŸ“Š ç²å–åˆ° {len(hist_data)} ç­†æ­·å²æ•¸æ“š")

        # å˜—è©¦ç²å–ç•¶å¤©çš„åˆ†é˜ç´šæ•¸æ“š
        try:
            logger.info("ğŸ”„ æ­£åœ¨ç²å–ç•¶å¤©è©³ç´°æ•¸æ“š...")
            recent_data = gold_ticker.history(
                period='2d',
                interval='1m'
            )

            if not recent_data.empty:
                today = datetime.now().date()
                today_data = recent_data[recent_data.index.date >= today]

                if not today_data.empty:
                    latest_price = today_data['Close'].iloc[-1]
                    latest_time = today_data.index[-1]

                    logger.info(f"ğŸ“Š ä»Šæ—¥æ•¸æ“š: {len(today_data)} ç­†ï¼Œæœ€æ–°åƒ¹æ ¼: ${latest_price:.2f}")
                    logger.info(f"ğŸ“… åŸå§‹æ™‚é–“: {latest_time}")

                    # æ›´æ–°æ­·å²æ•¸æ“šä¸­çš„æœ€æ–°åƒ¹æ ¼
                    if len(hist_data) > 0:
                        last_date = hist_data.index[-1].date()
                        if last_date == today:
                            # æ›´æ–°ä»Šå¤©çš„æ•¸æ“š
                            hist_data.loc[hist_data.index[-1], 'Close'] = latest_price
                            hist_data.loc[hist_data.index[-1], 'High'] = max(
                                hist_data.loc[hist_data.index[-1], 'High'], latest_price
                            )
                            hist_data.loc[hist_data.index[-1], 'Low'] = min(
                                hist_data.loc[hist_data.index[-1], 'Low'], latest_price
                            )
                            logger.info("âœ… å·²æ›´æ–°ä»Šæ—¥æ•¸æ“š")
                        else:
                            # æ·»åŠ ä»Šå¤©çš„æ•¸æ“š
                            new_row = pd.DataFrame({
                                'Open': [today_data['Open'].iloc[0]],
                                'High': [today_data['High'].max()],
                                'Low': [today_data['Low'].min()],
                                'Close': [latest_price],
                                'Volume': [today_data['Volume'].sum()]
                            }, index=[latest_time.replace(hour=0, minute=0, second=0, microsecond=0)])
                            hist_data = pd.concat([hist_data, new_row])
                            logger.info("âœ… å·²æ·»åŠ ä»Šæ—¥æ•¸æ“š")

                    # ä¿®æ­£æ™‚å€å•é¡Œï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“ (+8)
                    if hasattr(latest_time, 'tz_localize'):
                        # å¦‚æœæ˜¯æ™‚å€æ„ŸçŸ¥çš„æ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        if latest_time.tz is None:
                            # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                            latest_time_local = latest_time + timedelta(hours=8)
                        else:
                            # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                            latest_time_local = latest_time.tz_convert('Asia/Taipei')
                    else:
                        # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        latest_time_local = latest_time + timedelta(hours=8)
                    
                    latest_time_formatted = latest_time_local.strftime('%Y-%m-%d %H:%M')
                    logger.info(f"âœ… ç•¶å¤©æ•¸æ“šè™•ç†å®Œæˆï¼Œæœ€æ–°æ™‚é–“: {latest_time_formatted}")
                else:
                    logger.info("â„¹ï¸ ç•¶å¤©æš«ç„¡äº¤æ˜“æ•¸æ“š")
            else:
                logger.info("â„¹ï¸ ç„¡æ³•ç²å–ç•¶å¤©è©³ç´°æ•¸æ“š")

        except Exception as e:
            logger.warning(f"âš ï¸ ç²å–ç•¶å¤©æ•¸æ“šæ™‚å‡ºç¾å•é¡Œ: {e}")

        if hist_data.empty:
            raise ValueError("ç„¡æ³•ç²å–æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥æˆ–APIç‹€æ…‹")

        # ç²å–å¸‚å ´è³‡è¨Š
        info = None
        try:
            info = gold_ticker.info
            logger.info(f"ğŸ“‹ ç²å–å¸‚å ´è³‡è¨Š: {info.get('longName', 'N/A') if info else 'N/A'}")
        except Exception as info_error:
            logger.warning(f"âš ï¸ ç„¡æ³•ç²å–å¸‚å ´è³‡è¨Š: {info_error}")

        current_price = hist_data['Close'].iloc[-1] if not hist_data.empty else None

        logger.info(f"âœ… æ•¸æ“šç²å–å®Œæˆ:")
        logger.info(f"   æœ€çµ‚æ•¸æ“šé»æ•¸: {len(hist_data)}")
        logger.info(f"   æœ€æ–°åƒ¹æ ¼: ${current_price:.2f}")
        logger.info(f"   æœ€å¾Œæ›´æ–°: {hist_data.index[-1].strftime('%Y-%m-%d %H:%M')}")

        # ç²å–æœ€æ–°çš„è™•ç†æ™‚é–“
        latest_processing_time = None
        if 'latest_time_formatted' in locals():
            latest_processing_time = latest_time_formatted
        else:
            # ä¿®æ­£æ™‚å€å•é¡Œï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“ (+8)
            last_time = hist_data.index[-1]
            if hasattr(last_time, 'tz_localize'):
                if last_time.tz is None:
                    # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    last_time_local = last_time + timedelta(hours=8)
                else:
                    # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    last_time_local = last_time.tz_convert('Asia/Taipei')
            else:
                # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                last_time_local = last_time + timedelta(hours=8)
            latest_processing_time = last_time_local.strftime('%Y-%m-%d %H:%M')

        return hist_data, info, current_price, latest_processing_time

    except Exception as e:
        logger.error(f"âŒ ç²å–æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None, None


def calculate_gold_statistics(data):
    """è¨ˆç®—é»ƒé‡‘çµ±è¨ˆæ•¸æ“š"""
    if data is None or data.empty:
        return {}

    try:
        close_prices = data['Close']

        stats = {
            'current_price': float(close_prices.iloc[-1]),
            'max_price': float(close_prices.max()),
            'min_price': float(close_prices.min()),
            'avg_price': float(close_prices.mean()),
            'price_change': float(close_prices.iloc[-1] - close_prices.iloc[0]),
            'price_change_pct': float(((close_prices.iloc[-1] - close_prices.iloc[0]) / close_prices.iloc[0]) * 100),
            'volatility': float(close_prices.std()),
            'latest_date': close_prices.index[-1]
        }

        logger.info(f"ğŸ“Š çµ±è¨ˆè¨ˆç®—å®Œæˆ: ç•¶å‰=${stats['current_price']:.2f}, è®ŠåŒ–={stats['price_change']:+.2f}")
        return stats
    except Exception as e:
        logger.error(f"âŒ çµ±è¨ˆè¨ˆç®—å¤±æ•—: {e}")
        return {}


def calculate_technical_indicators_enhanced(hist_data):
    """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ - å¢å¼·ç‰ˆæœ¬"""
    technical_indicators = {}

    try:
        close_prices = hist_data['Close'].dropna()

        if len(close_prices) >= 20:
            ma_20 = close_prices.rolling(window=20).mean().iloc[-1]
            if not pd.isna(ma_20):
                technical_indicators["ma_20"] = float(ma_20)

        if len(close_prices) >= 50:
            ma_50 = close_prices.rolling(window=50).mean().iloc[-1]
            if not pd.isna(ma_50):
                technical_indicators["ma_50"] = float(ma_50)

        if len(close_prices) >= 14:
            rsi = calculate_rsi(close_prices.values)
            if rsi is not None:
                technical_indicators["rsi"] = rsi

        # é¡å¤–æŠ€è¡“æŒ‡æ¨™
        if len(close_prices) >= 5:
            technical_indicators["volatility_5d"] = float(close_prices.tail(5).std())

        if len(close_prices) >= 20 and "ma_20" in technical_indicators:
            technical_indicators["price_vs_ma20"] = float(
                (close_prices.iloc[-1] / technical_indicators["ma_20"] - 1) * 100)

        logger.info(f"ğŸ“ˆ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œæˆ: {len(technical_indicators)} å€‹æŒ‡æ¨™")

    except Exception as e:
        logger.warning(f"âš ï¸ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—éŒ¯èª¤: {e}")

    return technical_indicators


def calculate_rsi(prices, periods=14):
    """è¨ˆç®— RSI æŠ€è¡“æŒ‡æ¨™"""
    try:
        if len(prices) < periods + 1:
            return None

        prices = np.array(prices, dtype=float)
        prices = prices[~np.isnan(prices)]

        if len(prices) < periods + 1:
            return None

        deltas = np.diff(prices)

        if len(deltas) < periods:
            return None

        up_moves = np.where(deltas > 0, deltas, 0)
        down_moves = np.where(deltas < 0, -deltas, 0)

        if len(up_moves) >= periods and len(down_moves) >= periods:
            avg_up = np.mean(up_moves[-periods:])
            avg_down = np.mean(down_moves[-periods:])

            if avg_down == 0:
                return 100.0

            rs = avg_up / avg_down
            rsi = 100 - (100 / (1 + rs))
            return round(float(rsi), 1)

        return None

    except Exception as e:
        logger.warning(f"âš ï¸ RSI è¨ˆç®—éŒ¯èª¤: {e}")
        return None


def determine_market_status():
    """åˆ¤æ–·å¸‚å ´ç‹€æ…‹"""
    try:
        now = datetime.now()
        weekday = now.weekday()  # 0=Monday, 6=Sunday
        hour = now.hour

        # ç°¡åŒ–çš„å¸‚å ´é–‹æ”¾é‚è¼¯
        if weekday < 5:  # Monday to Friday
            if 18 <= hour or hour <= 17:
                return "open"
            else:
                return "closed"
        elif weekday == 6:  # Sunday
            if hour >= 18:
                return "open"

        return "closed"
    except Exception:
        return "unknown"


def get_market_name(info):
    """ç²å–å¸‚å ´åç¨±"""
    try:
        if isinstance(info, dict) and info:
            return info.get('longName', 'Gold Futures (GC=F)')
        return 'Gold Futures (GC=F)'
    except Exception as e:
        logger.error(f"âŒ ç²å–å¸‚å ´åç¨±å¤±æ•—: {e}")
        return 'Gold Futures (GC=F)'


def create_mock_gold_data(period: str):
    """å‰µå»ºæ¨¡æ“¬é»ƒé‡‘åƒ¹æ ¼æ•¸æ“šä½œç‚ºå‚™é¸æ–¹æ¡ˆ"""
    logger.info("ğŸ”§ ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™é¸æ–¹æ¡ˆ")

    base_price = 2025.50
    current_price = base_price + np.random.uniform(-10, 10)
    change = np.random.uniform(-20, 20)
    change_percent = (change / base_price) * 100

    # æ ¹æ“šæ™‚é–“æœŸé–“ç”Ÿæˆæ¨¡æ“¬åœ–è¡¨æ•¸æ“š
    period_days = {
        '1d': 1, '5d': 5, '1mo': 30, '3mo': 90,
        '6mo': 180, '1y': 365
    }

    days = period_days.get(period, 365)
    chart_data = []

    for i in range(min(days, 100)):  # æœ€å¤š100å€‹æ•¸æ“šé»
        date = datetime.now() - timedelta(days=days - i - 1)
        price_variation = np.random.uniform(-0.02, 0.02)  # 2%çš„æ³¢å‹•
        price = base_price * (1 + price_variation)

        chart_data.append({
            "time": date.isoformat(),
            "price": round(price, 2),
            "high": round(price * 1.005, 2),
            "low": round(price * 0.995, 2),
            "open": round(price * (1 + np.random.uniform(-0.001, 0.001)), 2),
            "volume": np.random.randint(1000, 10000)
        })

    logger.info(f"ğŸ”§ ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š: {len(chart_data)} å€‹æ•¸æ“šé»")

    return {
        "status": "success",
        "data": {
            "symbol": "GC=F",
            "name": "Gold Futures (æ¨¡æ“¬æ•¸æ“š)",
            "current_price": round(current_price, 2),
            "change": round(change, 2),
            "change_percent": round(change_percent, 2),
            "high_24h": round(current_price * 1.015, 2),
            "low_24h": round(current_price * 0.985, 2),
            "avg_price": round(base_price, 2),
            "volatility": round(np.random.uniform(10, 50), 2),
            "volume_24h": np.random.randint(50000, 200000),
            "currency": "USD",
            "unit": "per ounce",
            "last_updated": datetime.now().isoformat(),
            "chart_data": chart_data,
            "market_status": "open",
            "technical_indicators": {
                "ma_20": round(current_price * 0.998, 2),
                "ma_50": round(current_price * 1.002, 2),
                "rsi": round(np.random.uniform(30, 70), 1)
            },
            "period": period,
            "interval": "1d",
            "data_points": len(chart_data),
            "trading_days": len(chart_data)
        },
        "system_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "next_update": (datetime.now() + timedelta(minutes=5)).strftime("%Y-%m-%d %H:%M:%S"),
        "data_source": "Mock Data (Yahoo Finance ä¸å¯ç”¨)"
    }


@app.post("/api/send-mail-to-n8n")
async def send_mail_to_n8n(mail_data: MailSenderRequest):
    """ç™¼é€éƒµä»¶æ•¸æ“šåˆ° N8N webhook"""
    try:
        logger.info(f"ğŸ“§ æ”¶åˆ°éƒµä»¶ç™¼é€è«‹æ±‚:")
        logger.info(f"   æ”¶ä»¶äºº: {mail_data.recipient_email}")
        logger.info(f"   è‡ªè¨‚è¨Šæ¯: {mail_data.custom_message[:50] if mail_data.custom_message else 'ç„¡'}...")
        logger.info(f"   ä¸»é¡Œ: {mail_data.subject}")
        
        if not stored_data:
            logger.error("âŒ æ²’æœ‰å¯ç”¨çš„å¸‚å ´åˆ†æè³‡æ–™")
            raise HTTPException(status_code=400, detail="æ²’æœ‰å¯ç”¨çš„å¸‚å ´åˆ†æè³‡æ–™")

        logger.info(f"ğŸ“Š ç•¶å‰å„²å­˜æ•¸æ“š: {len(stored_data)} å€‹æ¬„ä½")
        logger.info(f"   æƒ…æ„Ÿåˆ†æ•¸: {stored_data.get('average_sentiment_score', 'N/A')}")
        logger.info(f"   å…§å®¹é•·åº¦: {len(stored_data.get('message_content', ''))} å­—å…ƒ")

        # æ§‹å»ºç™¼é€åˆ° N8N çš„æ•¸æ“šçµæ§‹
        send_data = {
            **stored_data,
            "mail_config": {
                "recipient_email": str(mail_data.recipient_email),
                "sender_name": mail_data.sender_name or "å¸‚å ´åˆ†æç³»çµ±",
                "subject": mail_data.subject or "å¸‚å ´åˆ†æå ±å‘Š",
                "priority": mail_data.priority or "normal",
                "mail_type": mail_data.mail_type or "daily",
                "custom_message": mail_data.custom_message or "",
                "include_charts": mail_data.include_charts,
                "include_recommendations": mail_data.include_recommendations,
                "include_risk_warning": mail_data.include_risk_warning
            },
            "system_info": {
                "send_timestamp": datetime.now().isoformat(),
                "system_version": CONFIG['SYSTEM_INFO']['version'],
                "source": "mail-sender-page"
            },
            "sentiment_analysis": {
                "score": stored_data.get("average_sentiment_score", 0),
                "text": get_sentiment_text(stored_data.get("average_sentiment_score", 0)),
                "emoji": get_market_emoji(stored_data.get("average_sentiment_score", 0))
            }
        }

        # logger.info(f"ğŸ“¤ æº–å‚™ç™¼é€æ•¸æ“šåˆ° N8N:")
        # logger.info(f"   Webhook URL: {CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']}")
        # logger.info(f"   æ•¸æ“šå¤§å°: {len(json.dumps(send_data, ensure_ascii=False))} å­—å…ƒ")
        #
        # # è¼¸å‡ºå®Œæ•´çš„ JSON æ•¸æ“š
        # logger.info("ğŸ“‹ ç™¼é€åˆ° N8N çš„å®Œæ•´ JSON æ•¸æ“š:")
        # logger.info(json.dumps(send_data, ensure_ascii=False, indent=2))
        #
        # logger.info("ğŸ“¤ é–‹å§‹ç™¼é€æ•¸æ“šåˆ° N8N...")

        response = requests.post(
            CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url'],
            json=send_data,
            headers={'Content-Type': 'application/json'},
            timeout=CONFIG['WEBHOOK_CONFIG']['timeout']
        )

        logger.info(f"ğŸ“¡ N8N å›æ‡‰ç‹€æ…‹: {response.status_code}")
        logger.info(f"ğŸ“¡ N8N å›æ‡‰å…§å®¹: {response.text[:200]}...")

        if response.status_code == 200:
            logger.info("âœ… éƒµä»¶æ•¸æ“šå·²æˆåŠŸç™¼é€åˆ° N8N")
            return {
                "status": "success",
                "message": f"éƒµä»¶æ•¸æ“šå·²æˆåŠŸç™¼é€åˆ° N8N",
                "sent_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "recipient": str(mail_data.recipient_email),
                "n8n_response": response.text[:100] if response.text else "ç„¡å›æ‡‰å…§å®¹"
            }
        else:
            logger.error(f"âŒ N8N webhook å›æ‡‰éŒ¯èª¤: {response.status_code} - {response.text}")
            raise HTTPException(status_code=response.status_code, detail=f"N8N webhook å›æ‡‰éŒ¯èª¤: {response.text}")

    except requests.exceptions.Timeout:
        logger.error("âŒ è«‹æ±‚è¶…æ™‚")
        raise HTTPException(status_code=500, detail="è«‹æ±‚è¶…æ™‚")
    except requests.exceptions.ConnectionError:
        logger.error("âŒ ç„¡æ³•é€£æ¥åˆ° N8N webhook")
        raise HTTPException(status_code=500, detail="ç„¡æ³•é€£æ¥åˆ° N8N webhook")
    except Exception as e:
        logger.error(f"âŒ ç™¼é€éƒµä»¶åˆ° N8N å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç™¼é€å¤±æ•—: {str(e)}")


@app.get("/api/test-n8n-connection")
async def test_n8n_connection():
    """æ¸¬è©¦ N8N é€£æ¥"""
    try:
        response = requests.get(
            CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url'],
            timeout=10
        )
        return {
            "status": "success",
            "message": "N8N é€£æ¥æ­£å¸¸",
            "status_code": response.status_code,
            "url": CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"N8N é€£æ¥å¤±æ•—: {str(e)}",
            "url": CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']
        }


@app.get("/api/debug-stored-data")
async def debug_stored_data():
    """èª¿è©¦ç«¯é» - æŸ¥çœ‹ç•¶å‰å­˜å„²çš„æ•¸æ“šçµæ§‹"""
    try:
        if not stored_data:
            return {
                "status": "warning",
                "message": "æ²’æœ‰å­˜å„²çš„æ•¸æ“š",
                "data": None,
                "timestamp": datetime.now().isoformat()
            }
        
        # æ§‹å»ºç¤ºä¾‹éƒµä»¶æ•¸æ“šï¼ˆä¸å¯¦éš›ç™¼é€ï¼‰
        sample_mail_data = {
            "recipient_email": "test@example.com",
            "custom_message": "é€™æ˜¯ä¸€å€‹æ¸¬è©¦è¨Šæ¯"
        }
        
        # æ¨¡æ“¬éƒµä»¶ç™¼é€æ™‚çš„æ•¸æ“šçµæ§‹
        sample_send_data = {
            **stored_data,
            "mail_config": {
                "recipient_email": sample_mail_data["recipient_email"],
                "sender_name": "å¸‚å ´åˆ†æç³»çµ±",
                "subject": "å¸‚å ´åˆ†æå ±å‘Š",
                "priority": "normal",
                "mail_type": "daily",
                "custom_message": sample_mail_data["custom_message"],
                "include_charts": False,
                "include_recommendations": False,
                "include_risk_warning": False
            },
            "system_info": {
                "send_timestamp": datetime.now().isoformat(),
                "system_version": CONFIG['SYSTEM_INFO']['version'],
                "source": "debug-endpoint"
            },
            "sentiment_analysis": {
                "score": stored_data.get("average_sentiment_score", 0),
                "text": get_sentiment_text(stored_data.get("average_sentiment_score", 0)),
                "emoji": get_market_emoji(stored_data.get("average_sentiment_score", 0))
            }
        }
        
        return {
            "status": "success",
            "message": "ç•¶å‰å­˜å„²çš„æ•¸æ“šçµæ§‹",
            "json_data": sample_send_data,
            "timestamp": datetime.now().isoformat(),
            "webhook_url": CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']
        }
        
    except Exception as e:
        logger.error(f"âŒ èª¿è©¦æ•¸æ“šç«¯é»éŒ¯èª¤: {str(e)}")
        return {
            "status": "error",
            "message": f"èª¿è©¦æ•¸æ“šå¤±æ•—: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }


@app.get("/health")
async def health_check():
    """ç³»çµ±å¥åº·æª¢æŸ¥ - å¢å¼·ç‰ˆæœ¬"""
    uptime = datetime.now() - system_stats["uptime_start"]

    # æ¸¬è©¦é»ƒé‡‘åƒ¹æ ¼ API
    gold_api_status = "healthy"
    try:
        import yfinance as yf
        test_ticker = yf.Ticker("GC=F")
        test_data = test_ticker.history(period="1d", interval="1d")
        if test_data.empty:
            gold_api_status = "degraded"
    except Exception:
        gold_api_status = "unhealthy"

    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "system": CONFIG['SYSTEM_INFO']['name'],
        "version": CONFIG['SYSTEM_INFO']['version'],
        "has_market_data": len(stored_data) > 0,
        "uptime": str(uptime).split('.')[0],
        "environment": os.getenv('ENVIRONMENT', 'development'),
        "stats": system_stats,
        "features": {
            "gold_price_api": gold_api_status,
            "market_analysis": "healthy",
            "mail_sender": "healthy",
            "real_time_updates": "healthy"
        },
        "services": {
            "yfinance": gold_api_status,
            "n8n_webhook": "unknown",
            "static_files": "healthy"
        }
    }


# è¼”åŠ©å‡½æ•¸
def get_sentiment_text(score: float) -> str:
    """æ ¹æ“šæƒ…æ„Ÿåˆ†æ•¸è¿”å›æ–‡å­—æè¿°"""
    if score > 0.6:
        return "æ¥µåº¦æ¨‚è§€"
    elif score > 0.2:
        return "æ¨‚è§€"
    elif score > 0.1:
        return "ä¸­æ€§åæ¨‚è§€"
    elif score > -0.1:
        return "ä¸­æ€§"
    elif score > -0.2:
        return "ä¸­æ€§åæ‚²è§€"
    elif score > -0.6:
        return "æ‚²è§€"
    else:
        return "æ¥µåº¦æ‚²è§€"


def get_market_emoji(score: float) -> str:
    """æ ¹æ“šæƒ…æ„Ÿåˆ†æ•¸è¿”å›è¡¨æƒ…ç¬¦è™Ÿ"""
    if score > 0.6:
        return "ğŸš€ğŸ“ˆğŸ’š"
    elif score > 0.2:
        return "ğŸ“ˆğŸŸ¢ğŸ˜Š"
    elif score > 0.1:
        return "ğŸ“ŠğŸŸ¡ğŸ˜"
    elif score > -0.1:
        return "â¡ï¸âšªğŸ˜‘"
    elif score > -0.2:
        return "ğŸ“ŠğŸŸ¡ğŸ˜"
    elif score > -0.6:
        return "ğŸ“‰ğŸ”´ğŸ˜Ÿ"
    else:
        return "ğŸ’¥ğŸ“‰ğŸ˜±"


# å•Ÿå‹•äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    logger.info("ğŸš€ å¸‚å ´åˆ†æç³»çµ±å•Ÿå‹• - ä¿®æ­£ç‰ˆ")
    logger.info(f"ğŸ“¡ N8N Webhook: {CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']}")
    logger.info(f"ğŸŒ ä¸»ç¶²ç«™: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}")
    logger.info(f"ğŸ“§ éƒµä»¶é é¢: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}/mail")
    logger.info(f"ğŸ“– APIæ–‡æª”: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}/api/docs")

    # æ¸¬è©¦é»ƒé‡‘åƒ¹æ ¼ API
    try:
        logger.info("ğŸ” æ¸¬è©¦é»ƒé‡‘åƒ¹æ ¼ API...")
        import yfinance as yf
        test_ticker = yf.Ticker("GC=F")
        test_data = test_ticker.history(period="1d")
        if not test_data.empty:
            logger.info("âœ… é»ƒé‡‘åƒ¹æ ¼ API é€£æ¥æ­£å¸¸")
        else:
            logger.warning("âš ï¸ é»ƒé‡‘åƒ¹æ ¼ API å¯èƒ½æœ‰å•é¡Œï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
    except Exception as e:
        logger.warning(f"âš ï¸ é»ƒé‡‘åƒ¹æ ¼ API æ¸¬è©¦å¤±æ•—: {str(e)}ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")


# éŒ¯èª¤è™•ç†
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    logger.error(f"HTTPç•°å¸¸: {exc.status_code} - {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "status": "error",
            "message": exc.detail,
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url)
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"æœªè™•ç†çš„ç•°å¸¸: {str(exc)}")
    system_stats["errors"] += 1
    return JSONResponse(
        status_code=500,
        content={
            "status": "error",
            "message": "å…§éƒ¨æœå‹™å™¨éŒ¯èª¤",
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url)
        }
    )


def main():
    print("ğŸš€ å•Ÿå‹•å¸‚å ´åˆ†æç³»çµ± - ä¿®æ­£ç‰ˆ...")
    print(f"ğŸŒ ä¸»ç¶²ç«™: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}")
    print(f"ğŸ“§ éƒµä»¶é é¢: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}/mail")
    print(f"ğŸ“– APIæ–‡æª”: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}/api/docs")
    print(f"ğŸ“Š ç³»çµ±ç‰ˆæœ¬: {CONFIG['SYSTEM_INFO']['version']}")

    uvicorn.run(
        app,
        host=CONFIG['SERVER_CONFIG']['host'],
        port=CONFIG['SERVER_CONFIG']['port'],
        log_level="info",
        reload=CONFIG['SERVER_CONFIG'].get('debug', False)
    )


if __name__ == "__main__":
    main()