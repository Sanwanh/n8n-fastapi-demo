#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸‚å ´åˆ†æå ±å‘Šç³»çµ± - APIæœå‹™ (ä¿®æ­£ç‰ˆ)
ä¸»è¦ä¿®æ­£ï¼š
1. ä¿®æ­£ Pydantic é©—è­‰å™¨éŒ¯èª¤
2. ä¿®æ­£å¸‚å ´æ•¸æ“šé¡¯ç¤ºå•é¡Œ
3. å¢å¼·éŒ¯èª¤è™•ç†å’Œæ—¥èªŒ
4. ç¢ºä¿æ•¸æ“šæ­£ç¢ºå‚³éåˆ°å‰ç«¯
"""

import os
import sys
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional, Any
import asyncio

# ç¬¬ä¸‰æ–¹å¥—ä»¶
try:
    from fastapi import FastAPI, Request, HTTPException
    from fastapi.responses import JSONResponse, HTMLResponse
    from fastapi.staticfiles import StaticFiles
    from fastapi.middleware.cors import CORSMiddleware
    from pydantic import BaseModel, EmailStr, field_validator
    import uvicorn
    import requests
    import yfinance as yf
    import pandas as pd
    import numpy as np
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„å¥—ä»¶: {e}")
    print("è«‹åŸ·è¡Œ: pip install -r requirements.txt")
    sys.exit(1)

# è¨­å®šæ—¥èªŒ - å¢å¼·ç‰ˆæœ¬
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('logs/market_analysis.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
Path("logs").mkdir(exist_ok=True)
Path("data").mkdir(exist_ok=True)
Path("frontend/static").mkdir(parents=True, exist_ok=True)


# è¼‰å…¥é…ç½®
def load_config():
    return {
        'SERVER_CONFIG': {
            'host': os.getenv('SERVER_HOST', '0.0.0.0'),
            'port': int(os.getenv('SERVER_PORT', 8089)),
            'debug': os.getenv('DEBUG', 'False').lower() == 'true'
        },
        'WEBHOOK_CONFIG': {
            'send_url': os.getenv(
                'WEBHOOK_URL',
                'https://beloved-swine-sensibly.ngrok-free.app/webhook-test/ef5ac185-f41a-4a2d-9a78-33d329184c2'
            ),
            'n8n_webhook_url': 'https://beloved-swine-sensibly.ngrok-free.app/webhook/Webhook - Preview',
            'timeout': int(os.getenv('WEBHOOK_TIMEOUT', 30))
        },
        'SYSTEM_INFO': {
            'name': 'Market Analysis API',
            'version': '2.2.0',
            'description': 'æ™ºèƒ½å¸‚å ´åˆ†æAPIæœå‹™ - ä¿®æ­£RSIå’ŒMA50é¡¯ç¤ºå•é¡Œ'
        }
    }


CONFIG = load_config()


# è³‡æ–™æ¨¡å‹ - ä¿®æ­£ç‰ˆæœ¬
class N8NDataExtended(BaseModel):
    positive: int
    neutral: int
    negative: int
    summary: str
    score: int
    label: str
    emailReportHtml: str

    @field_validator('score')
    @classmethod
    def validate_score(cls, v):
        """é©—è­‰æƒ…æ„Ÿåˆ†æ•¸å¿…é ˆåœ¨åˆç†ç¯„åœå…§"""
        if not isinstance(v, (int, float)):
            raise ValueError('æƒ…æ„Ÿåˆ†æ•¸å¿…é ˆæ˜¯æ•¸å­—')
        if not 0 <= v <= 100:
            raise ValueError('æƒ…æ„Ÿåˆ†æ•¸å¿…é ˆåœ¨ 0 åˆ° 100 ä¹‹é–“')
        return int(v)

    @field_validator('positive', 'neutral', 'negative')
    @classmethod
    def validate_sentiment_counts(cls, v):
        """é©—è­‰æƒ…æ„Ÿæ•¸é‡å¿…é ˆæ˜¯éè² æ•´æ•¸"""
        if not isinstance(v, (int, float)):
            raise ValueError('æƒ…æ„Ÿæ•¸é‡å¿…é ˆæ˜¯æ•¸å­—')
        if v < 0:
            raise ValueError('æƒ…æ„Ÿæ•¸é‡ä¸èƒ½ç‚ºè² æ•¸')
        return int(v)

    @field_validator('summary', 'label', 'emailReportHtml')
    @classmethod
    def validate_text_fields(cls, v):
        """é©—è­‰æ–‡å­—æ¬„ä½"""
        if v is None:
            return ""
        return str(v).strip()


class MailSenderRequest(BaseModel):
    recipient_email: EmailStr
    sender_name: Optional[str] = "å¸‚å ´åˆ†æç³»çµ±"
    subject: Optional[str] = "å¸‚å ´åˆ†æå ±å‘Š"
    priority: Optional[str] = "normal"
    mail_type: Optional[str] = "daily"
    custom_message: Optional[str] = ""
    include_charts: bool = False
    include_recommendations: bool = False
    include_risk_warning: bool = False


# ç”Ÿå‘½é€±æœŸç®¡ç†
from contextlib import asynccontextmanager


@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ‡‰ç”¨ç”Ÿå‘½é€±æœŸç®¡ç†"""
    # å•Ÿå‹•æ™‚
    logger.info("ğŸš€ å¸‚å ´åˆ†æç³»çµ±å•Ÿå‹• - ä¿®æ­£ç‰ˆ")
    logger.info(f"ğŸ“¡ N8N Webhook: {CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']}")
    logger.info(f"ğŸŒ ä¸»ç¶²ç«™: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}")
    logger.info(f"ğŸ“§ éƒµä»¶é é¢: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}/mail")
    logger.info(f"ğŸ“– APIæ–‡æª”: http://{CONFIG['SERVER_CONFIG']['host']}:{CONFIG['SERVER_CONFIG']['port']}/api/docs")

    # æ¸¬è©¦é»ƒé‡‘åƒ¹æ ¼ API
    try:
        logger.info("ğŸ” æ¸¬è©¦é»ƒé‡‘åƒ¹æ ¼ API...")
        import yfinance as yf
        test_ticker = yf.Ticker("GC=F")
        test_data = test_ticker.history(period="1d")
        if not test_data.empty:
            logger.info("âœ… é»ƒé‡‘åƒ¹æ ¼ API é€£æ¥æ­£å¸¸")
        else:
            logger.warning("âš ï¸ é»ƒé‡‘åƒ¹æ ¼ API å¯èƒ½æœ‰å•é¡Œï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
    except Exception as e:
        logger.warning(f"âš ï¸ é»ƒé‡‘åƒ¹æ ¼ API æ¸¬è©¦å¤±æ•—: {str(e)}ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")

    yield

    # é—œé–‰æ™‚
    logger.info("ğŸ›‘ å¸‚å ´åˆ†æç³»çµ±é—œé–‰ä¸­...")


# åˆå§‹åŒ– FastAPI
app = FastAPI(
    title=CONFIG['SYSTEM_INFO']['name'],
    description=CONFIG['SYSTEM_INFO']['description'],
    version=CONFIG['SYSTEM_INFO']['version'],
    docs_url="/api/docs",
    redoc_url="/api/redoc",
    lifespan=lifespan
)

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ›è¼‰éœæ…‹æª”æ¡ˆ
app.mount("/static", StaticFiles(directory="frontend/static"), name="static")


# Web è·¯ç”±
@app.get("/", response_class=HTMLResponse)
async def home():
    """ä¸»é é¢ - é¡¯ç¤ºå¸‚å ´æ•¸æ“šå’Œé»ƒé‡‘åƒ¹æ ¼"""
    html_file = Path("frontend") / "index.html"
    if html_file.exists():
        with open(html_file, 'r', encoding='utf-8') as f:
            return HTMLResponse(content=f.read())
    return HTMLResponse(content="<h1>é¦–é æª”æ¡ˆä¸å­˜åœ¨</h1>", status_code=404)


@app.get("/mail", response_class=HTMLResponse)
async def mail_page():
    """éƒµä»¶ç™¼é€é é¢"""
    html_file = Path("frontend") / "mail.html"
    if html_file.exists():
        with open(html_file, 'r', encoding='utf-8') as f:
            return HTMLResponse(content=f.read())
    return HTMLResponse(content="<h1>éƒµä»¶é é¢æª”æ¡ˆä¸å­˜åœ¨</h1>", status_code=404)


# å…¨åŸŸè®Šæ•¸ - å¢å¼·ç‰ˆæœ¬
stored_data = {}
system_stats = {
    "total_reports": 0,
    "today_reports": 0,
    "last_reset": datetime.now().date(),
    "uptime_start": datetime.now(),
    "last_data_received": None,
    "api_calls": 0,
    "gold_price_calls": 0,
    "errors": 0
}


# API è·¯ç”±
@app.post("/api/n8n-data")
async def receive_n8n_data(request: Request):
    """æ¥æ”¶ä¾†è‡ª N8N çš„å¸‚å ´åˆ†æè³‡æ–™ - ä¿®æ­£ç‰ˆæœ¬"""
    try:
        global stored_data, system_stats

        raw_data = await request.json()
        logger.info(f"ğŸ“¨ æ”¶åˆ° N8N åŸå§‹è³‡æ–™å¤§å°: {len(json.dumps(raw_data, ensure_ascii=False))} å­—å…ƒ")
        logger.info(f"ğŸ“¨ æ”¶åˆ° N8N è³‡æ–™: {json.dumps(raw_data, ensure_ascii=False)[:500]}...")

        # å¢å¼·çš„æ•¸æ“šè™•ç†é‚è¼¯
        if isinstance(raw_data, list) and len(raw_data) > 0:
            market_data = raw_data[0]
            logger.info("âœ… è™•ç†é™£åˆ—æ ¼å¼æ•¸æ“šï¼Œå–ç¬¬ä¸€å€‹å…ƒç´ ")
        elif isinstance(raw_data, dict):
            market_data = raw_data
            logger.info("âœ… è™•ç†å­—å…¸æ ¼å¼æ•¸æ“š")
        else:
            logger.error(f"âŒ ç„¡æ•ˆçš„è³‡æ–™æ ¼å¼: {type(raw_data)}")
            raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„è³‡æ–™æ ¼å¼: {type(raw_data)}")

        # è©³ç´°è¨˜éŒ„æ¥æ”¶åˆ°çš„æ•¸æ“šæ¬„ä½
        logger.info(f"ğŸ“Š æ•¸æ“šæ¬„ä½: {list(market_data.keys())}")

        # æ•¸æ“šæ¸…ç†å’Œè½‰æ›
        def safe_int(value, default=0):
            """å®‰å…¨åœ°è½‰æ›ç‚ºæ•´æ•¸"""
            try:
                if value is None:
                    return default
                return int(float(value))
            except (ValueError, TypeError):
                return default

        def safe_str(value, default=""):
            """å®‰å…¨åœ°è½‰æ›ç‚ºå­—ç¬¦ä¸²"""
            try:
                if value is None:
                    return default
                return str(value).strip()
            except (ValueError, TypeError):
                return default

        # æ§‹å»ºå„²å­˜çš„æ•¸æ“š
        current_time = datetime.now()

        # è™•ç†emailReportå…§å®¹
        email_report = ""
        if "data" in market_data and isinstance(market_data["data"], dict):
            email_report = market_data["data"].get("emailReport", "")
            logger.info(f"ğŸ“§ æ‰¾åˆ°emailReportå…§å®¹ï¼Œé•·åº¦: {len(email_report)} å­—å…ƒ")
        elif "emailReport" in market_data:
            email_report = market_data.get("emailReport", "")
            logger.info(f"ğŸ“§ ç›´æ¥æ‰¾åˆ°emailReportå…§å®¹ï¼Œé•·åº¦: {len(email_report)} å­—å…ƒ")

        # ä½¿ç”¨å®‰å…¨è½‰æ›å‡½æ•¸è™•ç†æ•¸æ“š
        processed_data = {
            "positive": safe_int(market_data.get("positive", 0)),
            "neutral": safe_int(market_data.get("neutral", 0)),
            "negative": safe_int(market_data.get("negative", 0)),
            "summary": safe_str(market_data.get("summary", "")),
            "score": safe_int(market_data.get("score", 0)),
            "label": safe_str(market_data.get("label", "")),
            "emailReportHtml": safe_str(market_data.get("emailReportHtml", "")),
        }

        # é©—è­‰è™•ç†å¾Œçš„æ•¸æ“š
        try:
            validated_data = N8NDataExtended(**processed_data)
            logger.info("âœ… æ•¸æ“šé©—è­‰é€šé")
        except Exception as ve:
            logger.error(f"âŒ æ•¸æ“šé©—è­‰å¤±æ•—: {str(ve)}")
            logger.error(f"   åŸå§‹æ•¸æ“š: {processed_data}")
            raise HTTPException(status_code=400, detail=f"æ•¸æ“šé©—è­‰å¤±æ•—: {str(ve)}")

        stored_data = {
            **processed_data,
            "received_time": current_time.strftime("%Y-%m-%d %H:%M:%S"),
            "received_timestamp": current_time.isoformat(),
            "raw_data": market_data,
            "email_report": email_report,
            "data_source": "N8N Webhook",
            "processing_time": datetime.now().isoformat(),
            "validation_passed": True
        }

        # æ›´æ–°ç³»çµ±çµ±è¨ˆ
        system_stats["total_reports"] += 1
        system_stats["today_reports"] += 1
        system_stats["last_data_received"] = current_time.isoformat()

        logger.info(f"âœ… æˆåŠŸè™•ç† N8N è³‡æ–™:")
        logger.info(f"   æ­£é¢æƒ…æ„Ÿ: {stored_data['positive']}")
        logger.info(f"   ä¸­æ€§æƒ…æ„Ÿ: {stored_data['neutral']}")
        logger.info(f"   è² é¢æƒ…æ„Ÿ: {stored_data['negative']}")
        logger.info(f"   æƒ…æ„Ÿåˆ†æ•¸: {stored_data['score']}")
        logger.info(f"   æ¨™ç±¤: {stored_data['label']}")
        logger.info(f"   æ‘˜è¦é•·åº¦: {len(stored_data['summary'])} å­—å…ƒ")
        logger.info(f"   æ¥æ”¶æ™‚é–“: {stored_data['received_time']}")

        return {
            "status": "success",
            "message": "å¸‚å ´åˆ†æè³‡æ–™å·²æ¥æ”¶ä¸¦å„²å­˜",
            "data": stored_data,
            "received_at": current_time.isoformat(),
            "processed_fields": len(stored_data),
            "system_stats": system_stats
        }

    except ValueError as ve:
        logger.error(f"âŒ æ•¸æ“šé©—è­‰éŒ¯èª¤: {str(ve)}")
        system_stats["errors"] += 1
        raise HTTPException(status_code=400, detail=f"æ•¸æ“šé©—è­‰éŒ¯èª¤: {str(ve)}")
    except Exception as e:
        logger.error(f"âŒ æ¥æ”¶ N8N è³‡æ–™å¤±æ•—: {str(e)}")
        system_stats["errors"] += 1
        raise HTTPException(status_code=500, detail=f"æ¥æ”¶è³‡æ–™å¤±æ•—: {str(e)}")


@app.get("/api/current-data")
async def get_current_data():
    """å–å¾—ç›®å‰å„²å­˜çš„å¸‚å ´åˆ†æè³‡æ–™ - å¢å¼·ç‰ˆæœ¬"""
    try:
        system_stats["api_calls"] += 1

        # æª¢æŸ¥æ•¸æ“šæ˜¯å¦éæœŸï¼ˆè¶…é1å°æ™‚ï¼‰
        data_age_minutes = 0
        if stored_data and stored_data.get('received_timestamp'):
            try:
                received_time = datetime.fromisoformat(stored_data['received_timestamp'])
                data_age_minutes = (datetime.now() - received_time).total_seconds() / 60
            except Exception as e:
                logger.warning(f"âš ï¸ ç„¡æ³•è¨ˆç®—æ•¸æ“šå¹´é½¡: {e}")

        response_data = {
            "status": "success",
            "data": stored_data,
            "stats": system_stats,
            "timestamp": datetime.now().isoformat(),
            "has_data": len(stored_data) > 0,
            "data_age_minutes": data_age_minutes,
            "data_freshness": "fresh" if data_age_minutes < 60 else "stale" if data_age_minutes < 1440 else "very_old"
        }

        return response_data

    except Exception as e:
        logger.error(f"âŒ å–å¾—ç•¶å‰æ•¸æ“šå¤±æ•—: {str(e)}")
        system_stats["errors"] += 1
        raise HTTPException(status_code=500, detail=f"å–å¾—æ•¸æ“šå¤±æ•—: {str(e)}")


@app.get("/api/gold-price")
async def get_gold_price(period: str = "1y", interval: str = "1d"):
    """å–å¾—é»ƒé‡‘æœŸè²¨åƒ¹æ ¼ - å¢å¼·ç‰ˆæœ¬"""
    try:
        system_stats["gold_price_calls"] += 1

        # é©—è­‰åƒæ•¸
        valid_periods = ["1d", "5d", "1mo", "3mo", "6mo", "1y", "2y", "5y"]
        valid_intervals = ["1m", "5m", "15m", "30m", "1h", "1d"]

        if period not in valid_periods:
            logger.warning(f"ç„¡æ•ˆçš„æ™‚é–“æœŸé–“: {period}ï¼Œä½¿ç”¨é è¨­å€¼ 1y")
            period = "1y"

        if interval not in valid_intervals:
            logger.warning(f"ç„¡æ•ˆçš„æ™‚é–“é–“éš”: {interval}ï¼Œä½¿ç”¨é è¨­å€¼ 1d")
            interval = "1d"

        # ç²å–é»ƒé‡‘æœŸè²¨æ•¸æ“š
        try:
            hist_data, info, current_price, latest_processing_time = await get_gold_futures_data_enhanced(period,
                                                                                                          interval)

            if hist_data is None or hist_data.empty:
                logger.warning("âš ï¸ ä¸»è¦æ•¸æ“šæºç„¡æ•¸æ“šï¼Œä½¿ç”¨å‚™é¸æ–¹æ¡ˆ...")
                return create_mock_gold_data(period)

        except Exception as e:
            logger.error(f"âŒ yfinance æ•¸æ“šç²å–å¤±æ•—: {str(e)}")
            return create_mock_gold_data(period)

        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        stats = calculate_gold_statistics(hist_data)

        if not stats:
            logger.warning("âš ï¸ çµ±è¨ˆè¨ˆç®—å¤±æ•—ï¼Œä½¿ç”¨å‚™é¸æ•¸æ“š")
            return create_mock_gold_data(period)

        # æº–å‚™åœ–è¡¨æ•¸æ“š
        chart_data = []
        for idx, row in hist_data.iterrows():
            try:
                # ä¿®æ­£æ™‚å€å•é¡Œï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                if hasattr(idx, 'tz_localize'):
                    if idx.tz is None:
                        # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        idx_local = idx + timedelta(hours=8)
                    else:
                        # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        idx_local = idx.tz_convert('Asia/Taipei')
                else:
                    # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    idx_local = idx + timedelta(hours=8)

                data_point = {
                    "time": idx_local.strftime('%Y-%m-%d'),
                    "price": float(row['Close']) if not pd.isna(row['Close']) else stats['current_price'],
                    "high": float(row['High']) if not pd.isna(row['High']) else stats['current_price'],
                    "low": float(row['Low']) if not pd.isna(row['Low']) else stats['current_price'],
                    "open": float(row['Open']) if not pd.isna(row['Open']) else stats['current_price'],
                    "volume": int(row['Volume']) if not pd.isna(row['Volume']) and row['Volume'] > 0 else 0
                }
                chart_data.append(data_point)
            except Exception as point_error:
                logger.warning(f"âš ï¸ è™•ç†æ•¸æ“šé»æ™‚å‡ºéŒ¯: {point_error}")
                continue

        # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
        technical_indicators = calculate_technical_indicators_enhanced(hist_data)

        # è¨ˆç®—ç§»å‹•å¹³å‡ç·šæ•¸æ“š
        ma_lines = {}
        if len(hist_data) >= 5:
            ma_5_data = hist_data['Close'].rolling(window=5).mean().dropna()
            ma_5_line_data = []
            for idx, val in ma_5_data.items():
                # ç¢ºä¿æ™‚é–“æ ¼å¼èˆ‡åœ–è¡¨æ•¸æ“šä¸€è‡´ï¼Œä¸¦æ­£ç¢ºè™•ç†æ™‚å€
                if hasattr(idx, 'tz_localize'):
                    if idx.tz is None:
                        # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        idx_local = idx + timedelta(hours=8)
                    else:
                        # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        idx_local = idx.tz_convert('Asia/Taipei')
                else:
                    # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    idx_local = idx + timedelta(hours=8)

                ma_5_line_data.append({
                    'time': idx_local.strftime('%Y-%m-%d'),
                    'price': float(val)
                })
            ma_lines["ma_5"] = ma_5_line_data

        if len(hist_data) >= 20:
            ma_20_data = hist_data['Close'].rolling(window=20).mean().dropna()
            ma_20_line_data = []
            for idx, val in ma_20_data.items():
                # ç¢ºä¿æ™‚é–“æ ¼å¼èˆ‡åœ–è¡¨æ•¸æ“šä¸€è‡´ï¼Œä¸¦æ­£ç¢ºè™•ç†æ™‚å€
                if hasattr(idx, 'tz_localize'):
                    if idx.tz is None:
                        # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        idx_local = idx + timedelta(hours=8)
                    else:
                        # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        idx_local = idx.tz_convert('Asia/Taipei')
                else:
                    # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    idx_local = idx + timedelta(hours=8)

                ma_20_line_data.append({
                    'time': idx_local.strftime('%Y-%m-%d'),
                    'price': float(val)
                })
            ma_lines["ma_20"] = ma_20_line_data

        # è¨ˆç®—MA125ç·šï¼ˆæ›¿ä»£æœˆå¹³å‡ç·šï¼‰
        ma_125_line = calculate_ma125_line(hist_data)

        # è¨ˆç®—å­£å¹³å‡åƒ¹æ ¼ç·šï¼ˆæ›¿ä»£å¹´å¹³å‡ç·šï¼‰
        quarterly_average_line = calculate_quarterly_average_line(hist_data)

        # æª¢æ¸¬é»ƒé‡‘äº¤å‰å’Œæ­»äº¡äº¤å‰
        cross_signal = detect_golden_death_cross(hist_data)

        # åˆ¤æ–·å¸‚å ´ç‹€æ…‹
        market_status = determine_market_status()

        # ç²å–å¸‚å ´è³‡è¨Š
        market_name = get_market_name(info)

        # è¨ˆç®—ç•¶æ—¥é«˜å’Œç•¶æ—¥ä½
        today_high = None
        today_low = None
        try:
            # ç²å–ç•¶å¤©çš„æ•¸æ“š
            today = datetime.now().date()
            today_data = hist_data[hist_data.index.date == today]
            if not today_data.empty:
                today_high = float(today_data['High'].max())
                today_low = float(today_data['Low'].min())
            else:
                # å¦‚æœæ²’æœ‰ç•¶å¤©æ•¸æ“šï¼Œä½¿ç”¨æœ€è¿‘ä¸€å¤©çš„æ•¸æ“š
                if len(hist_data) > 0:
                    latest_data = hist_data.iloc[-1]
                    today_high = float(latest_data['High'])
                    today_low = float(latest_data['Low'])
        except Exception as e:
            logger.warning(f"âš ï¸ è¨ˆç®—ç•¶æ—¥é«˜ä½åƒ¹å¤±æ•—: {e}")
            today_high = stats['current_price']
            today_low = stats['current_price']

        # æº–å‚™å›æ‡‰æ•¸æ“š
        response_data = {
            "status": "success",
            "data": {
                "symbol": "GC=F",
                "name": market_name,
                "current_price": round(stats['current_price'], 2),
                "change": round(stats['price_change'], 2),
                "change_percent": round(stats['price_change_pct'], 2),
                "high_24h": round(stats['max_price'], 2),
                "low_24h": round(stats['min_price'], 2),
                "today_high": round(today_high, 2) if today_high else None,
                "today_low": round(today_low, 2) if today_low else None,
                "avg_price": round(stats['avg_price'], 2),
                "volatility": round(stats['volatility'], 2),
                "volume_24h": 0,  # ç§»é™¤äº¤æ˜“é‡é¡¯ç¤º
                "currency": "USD",
                "unit": "per ounce",
                "last_updated": stats['latest_date'].isoformat(),
                "last_updated_formatted": latest_processing_time,
                "chart_data": chart_data,
                "ma_lines": ma_lines,
                "ma_125_line": ma_125_line,
                "pivot_points": quarterly_average_line,  # è½‰æŠ˜é»æ•¸æ“š
                "cross_signal": cross_signal,
                "market_status": market_status,
                "technical_indicators": technical_indicators,
                "period": period,
                "interval": interval,
                "data_points": len(chart_data),
                "trading_days": len(hist_data),
                "data_source_info": {
                    "primary": "Yahoo Finance",
                    "realtime_updated": len(chart_data) > 0 and
                                        chart_data[-1]['time'].split('T')[0] == datetime.now().strftime('%Y-%m-%d')
                }
            },
            "system_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "next_update": (datetime.now() + timedelta(minutes=5)).strftime("%Y-%m-%d %H:%M:%S"),
            "data_source": "Yahoo Finance API (Enhanced)",
            "processing_stats": {
                "raw_data_points": len(hist_data),
                "processed_chart_points": len(chart_data),
                "technical_indicators_count": len(technical_indicators),
                "processing_time": datetime.now().isoformat()
            }
        }

        return response_data

    except Exception as e:
        logger.error(f"âŒ ç²å–é»ƒé‡‘åƒ¹æ ¼å¤±æ•—: {str(e)}")
        system_stats["errors"] += 1
        return create_mock_gold_data(period)


async def get_gold_futures_data_enhanced(period: str, interval: str):
    """ç²å–é»ƒé‡‘æœŸè²¨æ•¸æ“š - å¢å¼·ç‰ˆæœ¬"""
    try:
        # è¨ˆç®—æ™‚é–“ç¯„åœ
        period_days_map = {
            '1d': 1, '5d': 5, '1mo': 30, '3mo': 90,
            '6mo': 180, '1y': 365, '2y': 730, '5y': 1825
        }
        period_days = period_days_map.get(period, 365)

        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)

        # ä½¿ç”¨yfinanceç²å–æ•¸æ“š
        gold_ticker = yf.Ticker("GC=F")

        # ç²å–æ­·å²æ•¸æ“š
        hist_data = gold_ticker.history(
            start=start_date.strftime('%Y-%m-%d'),
            end=end_date.strftime('%Y-%m-%d'),
            interval=interval
        )

        # å˜—è©¦ç²å–ç•¶å¤©çš„åˆ†é˜ç´šæ•¸æ“š
        try:
            recent_data = gold_ticker.history(
                period='2d',
                interval='1m'
            )

            if not recent_data.empty:
                today = datetime.now().date()
                today_data = recent_data[recent_data.index.date >= today]

                if not today_data.empty:
                    latest_price = today_data['Close'].iloc[-1]
                    latest_time = today_data.index[-1]

                    # æ›´æ–°æ­·å²æ•¸æ“šä¸­çš„æœ€æ–°åƒ¹æ ¼
                    if len(hist_data) > 0:
                        last_date = hist_data.index[-1].date()
                        if last_date == today:
                            # æ›´æ–°ä»Šå¤©çš„æ•¸æ“š
                            hist_data.loc[hist_data.index[-1], 'Close'] = latest_price
                            hist_data.loc[hist_data.index[-1], 'High'] = max(
                                hist_data.loc[hist_data.index[-1], 'High'], latest_price
                            )
                            hist_data.loc[hist_data.index[-1], 'Low'] = min(
                                hist_data.loc[hist_data.index[-1], 'Low'], latest_price
                            )
                        else:
                            # æ·»åŠ ä»Šå¤©çš„æ•¸æ“š
                            new_row = pd.DataFrame({
                                'Open': [today_data['Open'].iloc[0]],
                                'High': [today_data['High'].max()],
                                'Low': [today_data['Low'].min()],
                                'Close': [latest_price],
                                'Volume': [today_data['Volume'].sum()]
                            }, index=[latest_time.replace(hour=0, minute=0, second=0, microsecond=0)])
                            hist_data = pd.concat([hist_data, new_row])

                    # ä¿®æ­£æ™‚å€å•é¡Œï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“ (+8)
                    if hasattr(latest_time, 'tz_localize'):
                        # å¦‚æœæ˜¯æ™‚å€æ„ŸçŸ¥çš„æ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        if latest_time.tz is None:
                            # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                            latest_time_local = latest_time + timedelta(hours=8)
                        else:
                            # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                            latest_time_local = latest_time.tz_convert('Asia/Taipei')
                    else:
                        # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                        latest_time_local = latest_time + timedelta(hours=8)

                    latest_time_formatted = latest_time_local.strftime('%Y-%m-%d %H:%M')
                else:
                    logger.info("â„¹ï¸ ç•¶å¤©æš«ç„¡äº¤æ˜“æ•¸æ“š")
            else:
                logger.info("â„¹ï¸ ç„¡æ³•ç²å–ç•¶å¤©è©³ç´°æ•¸æ“š")

        except Exception as e:
            logger.warning(f"âš ï¸ ç²å–ç•¶å¤©æ•¸æ“šæ™‚å‡ºç¾å•é¡Œ: {e}")

        if hist_data.empty:
            raise ValueError("ç„¡æ³•ç²å–æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥æˆ–APIç‹€æ…‹")

        # ç²å–å¸‚å ´è³‡è¨Š
        info = None
        try:
            info = gold_ticker.info
        except Exception as info_error:
            logger.warning(f"âš ï¸ ç„¡æ³•ç²å–å¸‚å ´è³‡è¨Š: {info_error}")

        current_price = hist_data['Close'].iloc[-1] if not hist_data.empty else None

        # ç²å–æœ€æ–°çš„è™•ç†æ™‚é–“
        latest_processing_time = None
        if 'latest_time_formatted' in locals():
            latest_processing_time = latest_time_formatted
        else:
            # ä¿®æ­£æ™‚å€å•é¡Œï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“ (+8)
            last_time = hist_data.index[-1]
            if hasattr(last_time, 'tz_localize'):
                if last_time.tz is None:
                    # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    last_time_local = last_time + timedelta(hours=8)
                else:
                    # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    last_time_local = last_time.tz_convert('Asia/Taipei')
            else:
                # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                last_time_local = last_time + timedelta(hours=8)
            latest_processing_time = last_time_local.strftime('%Y-%m-%d %H:%M')

        return hist_data, info, current_price, latest_processing_time

    except Exception as e:
        logger.error(f"âŒ ç²å–æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None, None, None


def calculate_gold_statistics(data):
    """è¨ˆç®—é»ƒé‡‘çµ±è¨ˆæ•¸æ“š"""
    if data is None or data.empty:
        return {}

    try:
        close_prices = data['Close']

        # è¨ˆç®—æ—¥è®ŠåŒ–ï¼ˆç•¶å‰åƒ¹æ ¼èˆ‡æ˜¨å¤©æ”¶ç›¤åƒ¹æ ¼çš„å·®é¡ï¼‰
        current_price = float(close_prices.iloc[-1])
        yesterday_price = float(close_prices.iloc[-2]) if len(close_prices) > 1 else current_price

        daily_change = current_price - yesterday_price
        daily_change_pct = ((daily_change / yesterday_price) * 100) if yesterday_price != 0 else 0

        # è¨ˆç®—å¹´åº¦æ¨™æº–å·®ï¼ˆä½¿ç”¨æ•´å€‹æ•¸æ“šé›†ï¼‰
        # ä½¿ç”¨ ddof=1 ä¾†è¨ˆç®—æ¨£æœ¬æ¨™æº–å·®ï¼Œèˆ‡å‰ç«¯çš„è¨ˆç®—æ–¹æ³•ä¿æŒä¸€è‡´
        annual_volatility = float(close_prices.std(ddof=1))

        stats = {
            'current_price': current_price,
            'max_price': float(close_prices.max()),
            'min_price': float(close_prices.min()),
            'avg_price': float(close_prices.mean()),
            'price_change': daily_change,  # æ—¥è®ŠåŒ–
            'price_change_pct': daily_change_pct,  # æ—¥è®ŠåŒ–ç™¾åˆ†æ¯”
            'volatility': annual_volatility,  # å¹´åº¦æ¨™æº–å·®
            'latest_date': close_prices.index[-1],
            'yesterday_price': yesterday_price  # æ·»åŠ æ˜¨å¤©åƒ¹æ ¼ç”¨æ–¼èª¿è©¦
        }

        return stats
    except Exception as e:
        logger.error(f"âŒ çµ±è¨ˆè¨ˆç®—å¤±æ•—: {e}")
        return {}


def calculate_technical_indicators_enhanced(hist_data):
    """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ - å¢å¼·ç‰ˆæœ¬"""
    technical_indicators = {}

    try:
        close_prices = hist_data['Close'].dropna()
        
        if len(close_prices) < 20:
            logger.warning("âš ï¸ æ•¸æ“šä¸è¶³20å¤©ï¼Œç„¡æ³•è¨ˆç®—å®Œæ•´æŠ€è¡“æŒ‡æ¨™")
            return technical_indicators

        # è¨ˆç®—ç§»å‹•å¹³å‡ç·š
        ma_5_data = close_prices.rolling(window=5).mean()
        ma_20_data = close_prices.rolling(window=20).mean()
        ma_50_data = close_prices.rolling(window=50).mean()
        
        # ç•¶å‰å€¼
        current_ma5 = float(ma_5_data.iloc[-1])
        current_ma20 = float(ma_20_data.iloc[-1])
        current_ma50 = float(ma_50_data.iloc[-1]) if not pd.isna(ma_50_data.iloc[-1]) else None
        current_price = float(close_prices.iloc[-1])
        
        # å‰ä¸€å¤©å€¼
        prev_ma5 = float(ma_5_data.iloc[-2]) if len(ma_5_data) > 1 else current_ma5
        prev_ma20 = float(ma_20_data.iloc[-2]) if len(ma_20_data) > 1 else current_ma20
        prev_ma50 = float(ma_50_data.iloc[-2]) if len(ma_50_data) > 1 and not pd.isna(ma_50_data.iloc[-2]) else current_ma50
        
        # MA5 è¶¨å‹¢ç®­é ­
        ma5_trend = "â†‘" if current_ma5 > prev_ma5 else "â†“" if current_ma5 < prev_ma5 else "="
        
        # MA20 è¶¨å‹¢ç®­é ­
        ma20_trend = "â†‘" if current_ma20 > prev_ma20 else "â†“" if current_ma20 < prev_ma20 else "="
        
        # MA50 è¶¨å‹¢ç®­é ­
        ma50_trend = "â†‘" if current_ma50 and prev_ma50 and current_ma50 > prev_ma50 else "â†“" if current_ma50 and prev_ma50 and current_ma50 < prev_ma50 else "=" if current_ma50 else ""
        
        # MA5 èˆ‡ MA20 ç›¸å°é—œä¿‚
        ma_relation = "MA5 > MA20" if current_ma5 > current_ma20 else "MA5 < MA20"
        
        # é»ƒé‡‘äº¤å‰å’Œæ­»äº¡äº¤å‰æª¢æ¸¬
        golden_cross = (prev_ma5 <= prev_ma20) and (current_ma5 > current_ma20) and (current_price > current_ma20)
        death_cross = (prev_ma5 >= prev_ma20) and (current_ma5 < current_ma20) and (current_price < current_ma20)
        
        # äº¤å‰ç‹€æ…‹
        if golden_cross:
            cross_status = "golden_cross"
            cross_message = "ğŸŸ¢ é»ƒé‡‘äº¤å‰"
        elif death_cross:
            cross_status = "death_cross"
            cross_message = "ğŸ”´ æ­»äº¡äº¤å‰"
        else:
            cross_status = "normal"
            cross_message = "âšª æ­£å¸¸"
        
        # RSI14 è¨ˆç®—
        rsi14 = calculate_rsi(close_prices.values, periods=14)
        prev_rsi14 = calculate_rsi(close_prices.values[:-1], periods=14) if len(close_prices) > 14 else rsi14
        rsi14_trend = "â†‘" if rsi14 and prev_rsi14 and rsi14 > prev_rsi14 else "â†“" if rsi14 and prev_rsi14 and rsi14 < prev_rsi14 else "=" if rsi14 else ""
        
        # ä¹–é›¢ç‡è¨ˆç®— - MA5èˆ‡MA20ä¹‹é–“çš„ä¹–é›¢ç‡
        # æ­£ç¢ºå…¬å¼: ((current_ma5 - current_ma20) / current_ma20) * 100
        if current_ma20 != 0:
            ma5_ma20_deviation = ((current_ma5 - current_ma20) / current_ma20) * 100
        else:
            ma5_ma20_deviation = 0
        
        # å‰ä¸€å¤©ä¹–é›¢ç‡
        prev_price = float(close_prices.iloc[-2]) if len(close_prices) > 1 else current_price
        prev_ma5 = float(ma_5_data.iloc[-2]) if len(ma_5_data) > 1 else current_ma5
        prev_ma20 = float(ma_20_data.iloc[-2]) if len(ma_20_data) > 1 else current_ma20
        
        # ä½¿ç”¨æ­£ç¢ºå…¬å¼è¨ˆç®—å‰ä¸€æœŸä¹–é›¢ç‡
        if prev_ma20 != 0:
            prev_ma5_ma20_deviation = ((prev_ma5 - prev_ma20) / prev_ma20) * 100
        else:
            prev_ma5_ma20_deviation = 0
        
        # ä¹–é›¢ç‡è¶¨å‹¢ç®­é ­ - ç°¡åŒ–é‚è¼¯
        # ç®­é ­è¡¨ç¤ºä¹–é›¢ç‡çš„è®ŠåŒ–æ–¹å‘ï¼Œèˆ‡å¸‚å ´è¶¨å‹¢ä¸€è‡´
        if ma5_ma20_deviation > prev_ma5_ma20_deviation:
            # ä¹–é›¢ç‡å¢åŠ ï¼ˆç„¡è«–æ­£è² ï¼‰
            ma5_ma20_deviation_trend = "â†‘"
        elif ma5_ma20_deviation < prev_ma5_ma20_deviation:
            # ä¹–é›¢ç‡æ¸›å°‘ï¼ˆç„¡è«–æ­£è² ï¼‰
            ma5_ma20_deviation_trend = "â†“"
        else:
            # æ²’æœ‰è®ŠåŒ–
            ma5_ma20_deviation_trend = "="
        
        # éç†±åˆ¤æ–·ï¼ˆÂ±10%ï¼‰
        ma5_ma20_overheated = abs(ma5_ma20_deviation) > 10
        
        # æ§‹å»ºæŠ€è¡“æŒ‡æ¨™
        technical_indicators.update({
            "ma_5": current_ma5,
            "ma_5_trend": ma5_trend,
            "ma_20": current_ma20,
            "ma_20_trend": ma20_trend,
            "ma_50": current_ma50,
            "ma_50_trend": ma50_trend,
            "ma_relation": ma_relation,
            "cross_status": cross_status,
            "cross_message": cross_message,
            "rsi14": rsi14,
            "rsi14_trend": rsi14_trend,
            "ma5_ma20_deviation": round(ma5_ma20_deviation, 2),
            "ma5_ma20_deviation_trend": ma5_ma20_deviation_trend,
            "ma5_ma20_overheated": ma5_ma20_overheated
        })

    except Exception as e:
        logger.warning(f"âš ï¸ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—éŒ¯èª¤: {e}")

    return technical_indicators


def calculate_rsi(prices, periods=14):
    """è¨ˆç®— RSI æŠ€è¡“æŒ‡æ¨™"""
    try:
        if len(prices) < periods + 1:
            logger.warning(f"âš ï¸ RSIè¨ˆç®—ï¼šæ•¸æ“šä¸è¶³ï¼Œéœ€è¦{periods + 1}å€‹æ•¸æ“šé»ï¼Œå¯¦éš›åªæœ‰{len(prices)}å€‹")
            return None

        # è½‰æ›ç‚ºnumpyæ•¸çµ„ä¸¦è™•ç†NaNå€¼
        prices = np.array(prices, dtype=float)
        valid_prices = prices[~np.isnan(prices)]

        if len(valid_prices) < periods + 1:
            logger.warning(f"âš ï¸ RSIè¨ˆç®—ï¼šæœ‰æ•ˆæ•¸æ“šä¸è¶³ï¼Œéœ€è¦{periods + 1}å€‹æ•¸æ“šé»ï¼Œå¯¦éš›åªæœ‰{len(valid_prices)}å€‹")
            return None

        # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–
        deltas = np.diff(valid_prices)

        if len(deltas) < periods:
            logger.warning(f"âš ï¸ RSIè¨ˆç®—ï¼šåƒ¹æ ¼è®ŠåŒ–æ•¸æ“šä¸è¶³ï¼Œéœ€è¦{periods}å€‹æ•¸æ“šé»ï¼Œå¯¦éš›åªæœ‰{len(deltas)}å€‹")
            return None

        # åˆ†é›¢ä¸Šæ¼²å’Œä¸‹è·Œ
        up_moves = np.where(deltas > 0, deltas, 0)
        down_moves = np.where(deltas < 0, -deltas, 0)

        # è¨ˆç®—æœ€è¿‘periodsæœŸçš„å¹³å‡ä¸Šæ¼²å’Œä¸‹è·Œ
        if len(up_moves) >= periods and len(down_moves) >= periods:
            avg_up = np.mean(up_moves[-periods:])
            avg_down = np.mean(down_moves[-periods:])

            # è™•ç†é™¤é›¶æƒ…æ³
            if avg_down == 0:
                if avg_up == 0:
                    return 50.0  # å¦‚æœæ²’æœ‰è®ŠåŒ–ï¼Œè¿”å›ä¸­æ€§å€¼
                else:
                    return 100.0  # åªæœ‰ä¸Šæ¼²ï¼Œè¿”å›æœ€å¤§å€¼

            # è¨ˆç®—ç›¸å°å¼·å¼±æ¯”å’ŒRSI
            rs = avg_up / avg_down
            rsi = 100 - (100 / (1 + rs))
            
            # ç¢ºä¿çµæœåœ¨æœ‰æ•ˆç¯„åœå…§
            rsi = max(0, min(100, rsi))
            
            logger.info(f"âœ… RSIè¨ˆç®—æˆåŠŸï¼š{rsi:.1f} (periods={periods})")
            return round(float(rsi), 1)
        else:
            logger.warning(f"âš ï¸ RSIè¨ˆç®—ï¼šæ•¸æ“šé»ä¸è¶³ï¼Œup_moves={len(up_moves)}, down_moves={len(down_moves)}, éœ€è¦{periods}")
            return None

    except Exception as e:
        logger.warning(f"âš ï¸ RSI è¨ˆç®—éŒ¯èª¤: {e}")
        return None


def calculate_quarterly_average_line(hist_data):
    """
    è¨ˆç®—è½‰æŠ˜é»ï¼ˆPivot Pointï¼‰- æ¯æœˆåˆè¨ˆç®—ä¸€æ¬¡ï¼Œè©²é»ç‚ºå‰ä¸‰å€‹æœˆæœ€é«˜åƒ¹èˆ‡æœ€ä½åƒ¹çš„å¹³å‡å€¼ï¼Œæ¯æœˆåªç”¢ç”Ÿä¸€å€‹é»ï¼Œä¸¦å¯é€£æˆæŠ˜ç·šåœ–ã€‚
    """
    try:
        # ç¢ºä¿ç´¢å¼•ç‚º DatetimeIndex
        if not isinstance(hist_data.index, pd.DatetimeIndex):
            hist_data.index = pd.to_datetime(hist_data.index)

        # çµ±ä¸€è™•ç†æ™‚å€å•é¡Œï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“ (+8)
        if hist_data.index.tz is None:
            # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
            hist_data.index = hist_data.index + timedelta(hours=8)
        else:
            # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
            hist_data.index = hist_data.index.tz_convert('Asia/Taipei')

        # ç§»é™¤æ™‚å€ä¿¡æ¯ï¼Œçµ±ä¸€ç‚ºæœ¬åœ°æ™‚é–“
        hist_data.index = hist_data.index.tz_localize(None)

        # ç¢ºä¿æ•¸æ“šæŒ‰æ™‚é–“æ’åº
        hist_data = hist_data.sort_index()

        if len(hist_data) < 90:
            logger.warning("âš ï¸ æ•¸æ“šä¸è¶³90å¤©ï¼Œç„¡æ³•è¨ˆç®—è½‰æŠ˜é»")
            return []

        points = []

        # ä¿®æ­£ï¼šä½¿ç”¨æ›´ç²¾ç¢ºçš„æœˆä»½è¨ˆç®—æ–¹æ³•
        # å°‡æ•¸æ“šæŒ‰æœˆä»½åˆ†çµ„
        hist_data['year_month'] = hist_data.index.to_period('M')
        monthly_groups = hist_data.groupby('year_month')

        # ç²å–æ‰€æœ‰æœˆä»½
        all_months = sorted(monthly_groups.groups.keys())

        # å¾ç¬¬4å€‹æœˆé–‹å§‹è¨ˆç®—ï¼ˆéœ€è¦å‰3å€‹æœˆçš„æ•¸æ“šï¼‰
        for i in range(3, len(all_months)):
            current_month = all_months[i]

            # ç²å–å‰ä¸‰å€‹æœˆçš„æ•¸æ“š
            prev3_months = all_months[i - 3:i]
            prev3_data = hist_data[hist_data['year_month'].isin(prev3_months)]

            if len(prev3_data) == 0:
                logger.warning(f"âš ï¸ æœˆä»½ {current_month} çš„å‰ä¸‰å€‹æœˆæ•¸æ“šä¸è¶³")
                continue

            # è¨ˆç®—å‰ä¸‰å€‹æœˆçš„æœ€é«˜åƒ¹å’Œæœ€ä½åƒ¹
            high = prev3_data['High'].max()
            low = prev3_data['Low'].min()
            pivot = (high + low) / 2

            # ç²å–ç•¶å‰æœˆä»½çš„æ•¸æ“š
            current_month_data = hist_data[hist_data['year_month'] == current_month]

            # ä¿®æ­£ï¼šç¢ºä¿æ¯å€‹æœˆéƒ½æœ‰ä¸€å€‹è½‰æŠ˜é»ï¼Œä½¿ç”¨ç•¶æœˆç¬¬ä¸€å€‹äº¤æ˜“æ—¥
            if len(current_month_data) > 0:
                # ä½¿ç”¨ç•¶æœˆç¬¬ä¸€å€‹äº¤æ˜“æ—¥
                first_trading_day = current_month_data.index.min()
                point_date = first_trading_day.strftime('%Y-%m-%d')
            else:
                # å¦‚æœç•¶æœˆæ²’æœ‰äº¤æ˜“æ•¸æ“šï¼Œä½¿ç”¨æœˆåˆæ—¥æœŸ
                point_date = current_month.to_timestamp().strftime('%Y-%m-%d')

            # ç²å–ç•¶æ—¥åƒ¹æ ¼é€²è¡Œæ¯”è¼ƒ
            current_price = None
            try:
                # å˜—è©¦ç²å–è½‰æŠ˜é»æ—¥æœŸç•¶å¤©çš„åƒ¹æ ¼
                pivot_date = pd.to_datetime(point_date)
                if pivot_date in hist_data.index:
                    current_price = float(hist_data.loc[pivot_date, 'Close'])
                else:
                    # å¦‚æœæ²’æœ‰ç•¶å¤©æ•¸æ“šï¼Œä½¿ç”¨æœ€è¿‘çš„åƒ¹æ ¼
                    current_price = float(hist_data['Close'].iloc[-1])
            except Exception as e:
                logger.warning(f"âš ï¸ ç²å–è½‰æŠ˜é»ç•¶æ—¥åƒ¹æ ¼å¤±æ•—: {e}")
                current_price = float(hist_data['Close'].iloc[-1])
            
            # åˆ¤æ–·åƒ¹æ ¼é—œä¿‚
            price_status = "bullish" if current_price > pivot else "bearish" if current_price < pivot else "neutral"
            
            points.append({
                'time': point_date,
                'price': float(pivot),
                'high': float(high),
                'low': float(low),
                'range': f"{prev3_months[0]}~{prev3_months[-1]}",
                'current_price': current_price,
                'price_status': price_status
            })

        # æŒ‰æ™‚é–“æ’åºç¢ºä¿æŠ˜ç·šåœ–æ­£ç¢ºé€£æ¥
        points.sort(key=lambda x: x['time'])

        logger.info(f"ğŸ“Š è½‰æŠ˜é»è¨ˆç®—å®Œæˆï¼Œå…± {len(points)} å€‹æ•¸æ“šé»")

        return points

    except Exception as e:
        logger.warning(f"âš ï¸ è½‰æŠ˜é»è¨ˆç®—éŒ¯èª¤: {e}")
        return []


def calculate_ma125_line(hist_data):
    """è¨ˆç®—MA125ç§»å‹•å¹³å‡ç·š"""
    try:
        # ç¢ºä¿æ•¸æ“šæœ‰æ—¥æœŸç´¢å¼•
        if not isinstance(hist_data.index, pd.DatetimeIndex):
            hist_data.index = pd.to_datetime(hist_data.index)

        if len(hist_data) < 125:
            logger.warning("âš ï¸ æ•¸æ“šä¸è¶³125å¤©ï¼Œç„¡æ³•è¨ˆç®—MA125")
            return []

        # è¨ˆç®—MA125
        ma_125_data = hist_data['Close'].rolling(window=125).mean().dropna()

        # è½‰æ›ç‚ºåœ–è¡¨æ•¸æ“šæ ¼å¼ï¼Œç¢ºä¿æ™‚é–“æ ¼å¼èˆ‡åœ–è¡¨æ•¸æ“šä¸€è‡´
        ma_125_line_data = []
        for idx, val in ma_125_data.items():
            # ç¢ºä¿æ™‚é–“æ ¼å¼èˆ‡åœ–è¡¨æ•¸æ“šä¸€è‡´ï¼Œä¸¦æ­£ç¢ºè™•ç†æ™‚å€
            if hasattr(idx, 'tz_localize'):
                if idx.tz is None:
                    # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    idx_local = idx + timedelta(hours=8)
                else:
                    # è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                    idx_local = idx.tz_convert('Asia/Taipei')
            else:
                # å‡è¨­æ˜¯UTCæ™‚é–“ï¼Œè½‰æ›ç‚ºå°åŒ—æ™‚é–“
                idx_local = idx + timedelta(hours=8)

            ma_125_line_data.append({
                'time': idx_local.strftime('%Y-%m-%d'),
                'price': float(val)
            })

        logger.info(f"ğŸ“Š MA125è¨ˆç®—å®Œæˆï¼Œå…± {len(ma_125_line_data)} å€‹æ•¸æ“šé»")

        return ma_125_line_data

    except Exception as e:
        logger.warning(f"âš ï¸ MA125è¨ˆç®—éŒ¯èª¤: {e}")
        return []


def detect_golden_death_cross(hist_data):
    """æª¢æ¸¬é»ƒé‡‘äº¤å‰å’Œæ­»äº¡äº¤å‰ - ä½¿ç”¨MA5ç©¿è¶ŠMA20ï¼ˆå·²æ•´åˆåˆ°æŠ€è¡“æŒ‡æ¨™ä¸­ï¼‰"""
    try:
        if len(hist_data) < 20:
            return {"golden_cross": False, "death_cross": False, "message": "", "status": "normal"}

        # è¨ˆç®—MA20å’ŒMA5
        ma_20 = hist_data['Close'].rolling(window=20).mean()
        ma_5 = hist_data['Close'].rolling(window=5).mean()

        # ç²å–æœ€æ–°å’Œå‰ä¸€å¤©çš„æ•¸æ“š
        current_ma20 = float(ma_20.iloc[-1])
        current_ma5 = float(ma_5.iloc[-1])
        prev_ma20 = float(ma_20.iloc[-2]) if len(ma_20) > 1 else current_ma20
        prev_ma5 = float(ma_5.iloc[-2]) if len(ma_5) > 1 else current_ma5
        current_price = float(hist_data['Close'].iloc[-1])

        # æª¢æ¸¬é»ƒé‡‘äº¤å‰ï¼ˆMA5å¾ä¸‹æ–¹ç©¿è¶ŠMA20ï¼Œä¸”æ”¶ç›¤åƒ¹é«˜æ–¼MA20ï¼‰
        golden_cross = bool((prev_ma5 <= prev_ma20) and (current_ma5 > current_ma20) and (current_price > current_ma20))

        # æª¢æ¸¬æ­»äº¡äº¤å‰ï¼ˆMA5å¾ä¸Šæ–¹ç©¿è¶ŠMA20ï¼Œä¸”æ”¶ç›¤åƒ¹ä½æ–¼MA20ï¼‰
        death_cross = bool((prev_ma5 >= prev_ma20) and (current_ma5 < current_ma20) and (current_price < current_ma20))

        message = ""
        status = "normal"
        if golden_cross:
            message = "ğŸŸ¢ é»ƒé‡‘äº¤å‰ï¼šMA5ç©¿è¶ŠMA20å‘ä¸Šï¼Œçœ‹æ¼²ä¿¡è™Ÿ"
            status = "golden_cross"
        elif death_cross:
            message = "ğŸ”´ æ­»äº¡äº¤å‰ï¼šMA5ç©¿è¶ŠMA20å‘ä¸‹ï¼Œçœ‹è·Œä¿¡è™Ÿ"
            status = "death_cross"
        else:
            message = "âšª æ­£å¸¸ï¼šMA5èˆ‡MA20ç„¡äº¤å‰ä¿¡è™Ÿ"
            status = "normal"

        return {
            "golden_cross": golden_cross,
            "death_cross": death_cross,
            "status": status,
            "message": message,
            "current_ma20": current_ma20,
            "current_ma5": current_ma5
        }

    except Exception as e:
        logger.warning(f"âš ï¸ äº¤å‰æª¢æ¸¬éŒ¯èª¤: {e}")
        return {"golden_cross": False, "death_cross": False, "message": "", "status": "normal"}


def determine_market_status():
    """åˆ¤æ–·å¸‚å ´ç‹€æ…‹ - é»ƒé‡‘æœŸè²¨å¸‚å ´æ™‚é–“ (ç¾æ±æ™‚é–“)"""
    try:
        from datetime import timezone, timedelta

        # ç²å–ç¾æ±æ™‚é–“
        # æ³¨æ„ï¼šé€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰è©²è€ƒæ…®å¤ä»¤æ™‚é–“
        # ç¾æ±æ™‚é–“ = UTC - 5å°æ™‚ (æ¨™æº–æ™‚é–“) æˆ– UTC - 4å°æ™‚ (å¤ä»¤æ™‚é–“)
        utc_now = datetime.now(timezone.utc)

        # ç°¡åŒ–ï¼šå‡è¨­æ˜¯æ¨™æº–æ™‚é–“ (UTC - 5)
        # å¯¦éš›æ‡‰ç”¨ä¸­æ‡‰è©²ä½¿ç”¨ pytz æˆ– zoneinfo ä¾†æ­£ç¢ºè™•ç†æ™‚å€
        est_offset = timedelta(hours=5)
        est_now = utc_now - est_offset

        weekday = est_now.weekday()  # 0=Monday, 6=Sunday
        hour = est_now.hour

        # é»ƒé‡‘æœŸè²¨å¸‚å ´æ™‚é–“ (ç¾æ±æ™‚é–“ EST)
        # é€±æ—¥ 6:00 PM - é€±äº” 5:00 PM (ç¾æ±æ™‚é–“)
        # é€±äº” 5:00 PM - é€±æ—¥ 6:00 PM ä¼‘å¸‚

        if weekday < 5:  # Monday to Friday
            return "open"  # é€±ä¸€åˆ°é€±äº”éƒ½æ˜¯é–‹å¸‚
        elif weekday == 5:  # Saturday
            return "closed"  # é€±å…­ä¼‘å¸‚
        elif weekday == 6:  # Sunday
            # é€±æ—¥ 6:00 PM (18:00) å¾Œé–‹å¸‚
            if hour >= 18:
                return "open"
            else:
                return "closed"
        else:
            return "closed"

    except Exception as e:
        logger.error(f"âŒ å¸‚å ´ç‹€æ…‹åˆ¤æ–·å¤±æ•—: {e}")
        return "unknown"


def get_market_name(info):
    """ç²å–å¸‚å ´åç¨±"""
    try:
        if isinstance(info, dict) and info:
            return info.get('longName', 'Gold Futures (GC=F)')
        return 'Gold Futures (GC=F)'
    except Exception as e:
        logger.error(f"âŒ ç²å–å¸‚å ´åç¨±å¤±æ•—: {e}")
        return 'Gold Futures (GC=F)'


def create_mock_gold_data(period: str):
    """å‰µå»ºæ¨¡æ“¬é»ƒé‡‘åƒ¹æ ¼æ•¸æ“šä½œç‚ºå‚™é¸æ–¹æ¡ˆ"""
    logger.info("ğŸ”§ ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™é¸æ–¹æ¡ˆ")

    base_price = 2025.50
    current_price = base_price + np.random.uniform(-10, 10)
    change = np.random.uniform(-20, 20)
    change_percent = (change / base_price) * 100

    # æ ¹æ“šæ™‚é–“æœŸé–“ç”Ÿæˆæ¨¡æ“¬åœ–è¡¨æ•¸æ“š
    period_days = {
        '1d': 1, '5d': 5, '1mo': 30, '3mo': 90,
        '6mo': 180, '1y': 365
    }

    days = period_days.get(period, 365)
    chart_data = []

    for i in range(min(days, 100)):  # æœ€å¤š100å€‹æ•¸æ“šé»
        date = datetime.now() - timedelta(days=days - i - 1)
        price_variation = np.random.uniform(-0.02, 0.02)  # 2%çš„æ³¢å‹•
        price = base_price * (1 + price_variation)

        chart_data.append({
            "time": date.isoformat(),
            "price": round(price, 2),
            "high": round(price * 1.005, 2),
            "low": round(price * 0.995, 2),
            "open": round(price * (1 + np.random.uniform(-0.001, 0.001)), 2),
            "volume": np.random.randint(1000, 10000)
        })

    logger.info(f"ğŸ”§ ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š: {len(chart_data)} å€‹æ•¸æ“šé»")

    return {
        "status": "success",
        "data": {
            "symbol": "GC=F",
            "name": "Gold Futures (æ¨¡æ“¬æ•¸æ“š)",
            "current_price": round(current_price, 2),
            "change": round(change, 2),
            "change_percent": round(change_percent, 2),
            "high_24h": round(current_price * 1.015, 2),
            "low_24h": round(current_price * 0.985, 2),
            "today_high": round(current_price * 1.008, 2),
            "today_low": round(current_price * 0.992, 2),
            "avg_price": round(base_price, 2),
            "volatility": round(np.random.uniform(10, 50), 2),
            "volume_24h": np.random.randint(50000, 200000),
            "currency": "USD",
            "unit": "per ounce",
            "last_updated": datetime.now().isoformat(),
            "chart_data": chart_data,
            "market_status": "open",
            "technical_indicators": {
                "ma_20": round(current_price * 0.998, 2),
                "ma_50": round(current_price * 1.002, 2),
                "rsi": round(np.random.uniform(30, 70), 1)
            },
            "period": period,
            "interval": "1d",
            "data_points": len(chart_data),
            "trading_days": len(chart_data)
        },
        "system_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "next_update": (datetime.now() + timedelta(minutes=5)).strftime("%Y-%m-%d %H:%M:%S"),
        "data_source": "Mock Data (Yahoo Finance ä¸å¯ç”¨)"
    }


@app.post("/api/send-mail-to-n8n")
async def send_mail_to_n8n(mail_data: MailSenderRequest):
    """ç™¼é€éƒµä»¶æ•¸æ“šåˆ° N8N webhook"""
    try:
        if not stored_data:
            logger.error("âŒ æ²’æœ‰å¯ç”¨çš„å¸‚å ´åˆ†æè³‡æ–™")
            raise HTTPException(status_code=400, detail="æ²’æœ‰å¯ç”¨çš„å¸‚å ´åˆ†æè³‡æ–™")

        # æ§‹å»ºç™¼é€åˆ° N8N çš„æ•¸æ“šçµæ§‹
        send_data = {
            **stored_data,
            "mail_config": {
                "recipient_email": str(mail_data.recipient_email),
                "sender_name": mail_data.sender_name or "å¸‚å ´åˆ†æç³»çµ±",
                "subject": mail_data.subject or "å¸‚å ´åˆ†æå ±å‘Š",
                "priority": mail_data.priority or "normal",
                "mail_type": mail_data.mail_type or "daily",
                "custom_message": mail_data.custom_message or "",
                "include_charts": mail_data.include_charts,
                "include_recommendations": mail_data.include_recommendations,
                "include_risk_warning": mail_data.include_risk_warning
            },
            "system_info": {
                "send_timestamp": datetime.now().isoformat(),
                "system_version": CONFIG['SYSTEM_INFO']['version'],
                "source": "mail-sender-page"
            },
            "sentiment_analysis": {
                "score": stored_data.get("score", 0),
                "text": get_sentiment_text(stored_data.get("score", 0)),
                "emoji": get_market_emoji(stored_data.get("score", 0))
            }
        }

        response = requests.post(
            CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url'],
            json=send_data,
            headers={'Content-Type': 'application/json'},
            timeout=CONFIG['WEBHOOK_CONFIG']['timeout']
        )

        if response.status_code == 200:
            return {
                "status": "success",
                "message": f"éƒµä»¶æ•¸æ“šå·²æˆåŠŸç™¼é€åˆ° N8N",
                "sent_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "recipient": str(mail_data.recipient_email),
                "n8n_response": response.text[:100] if response.text else "ç„¡å›æ‡‰å…§å®¹"
            }
        else:
            logger.error(f"âŒ N8N webhook å›æ‡‰éŒ¯èª¤: {response.status_code} - {response.text}")
            raise HTTPException(status_code=response.status_code, detail=f"N8N webhook å›æ‡‰éŒ¯èª¤: {response.text}")

    except requests.exceptions.Timeout:
        logger.error("âŒ è«‹æ±‚è¶…æ™‚")
        raise HTTPException(status_code=500, detail="è«‹æ±‚è¶…æ™‚")
    except requests.exceptions.ConnectionError:
        logger.error("âŒ ç„¡æ³•é€£æ¥åˆ° N8N webhook")
        raise HTTPException(status_code=500, detail="ç„¡æ³•é€£æ¥åˆ° N8N webhook")
    except Exception as e:
        logger.error(f"âŒ ç™¼é€éƒµä»¶åˆ° N8N å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç™¼é€å¤±æ•—: {str(e)}")


@app.get("/api/test-n8n-connection")
async def test_n8n_connection():
    """æ¸¬è©¦ N8N é€£æ¥"""
    try:
        response = requests.get(
            CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url'],
            timeout=10
        )
        return {
            "status": "success",
            "message": "N8N é€£æ¥æ­£å¸¸",
            "status_code": response.status_code,
            "url": CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"N8N é€£æ¥å¤±æ•—: {str(e)}",
            "url": CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']
        }


@app.get("/api/debug-stored-data")
async def debug_stored_data():
    """èª¿è©¦ç«¯é» - æŸ¥çœ‹ç•¶å‰å­˜å„²çš„æ•¸æ“šçµæ§‹"""
    try:
        if not stored_data:
            return {
                "status": "warning",
                "message": "æ²’æœ‰å­˜å„²çš„æ•¸æ“š",
                "data": None,
                "timestamp": datetime.now().isoformat()
            }

        # æ§‹å»ºç¤ºä¾‹éƒµä»¶æ•¸æ“šï¼ˆä¸å¯¦éš›ç™¼é€ï¼‰
        sample_mail_data = {
            "recipient_email": "test@example.com",
            "custom_message": "é€™æ˜¯ä¸€å€‹æ¸¬è©¦è¨Šæ¯"
        }

        # æ¨¡æ“¬éƒµä»¶ç™¼é€æ™‚çš„æ•¸æ“šçµæ§‹
        sample_send_data = {
            **stored_data,
            "mail_config": {
                "recipient_email": sample_mail_data["recipient_email"],
                "sender_name": "å¸‚å ´åˆ†æç³»çµ±",
                "subject": "å¸‚å ´åˆ†æå ±å‘Š",
                "priority": "normal",
                "mail_type": "daily",
                "custom_message": sample_mail_data["custom_message"],
                "include_charts": False,
                "include_recommendations": False,
                "include_risk_warning": False
            },
            "system_info": {
                "send_timestamp": datetime.now().isoformat(),
                "system_version": CONFIG['SYSTEM_INFO']['version'],
                "source": "debug-endpoint"
            },
            "sentiment_analysis": {
                "score": stored_data.get("score", 0),
                "text": get_sentiment_text(stored_data.get("score", 0)),
                "emoji": get_market_emoji(stored_data.get("score", 0))
            }
        }

        return {
            "status": "success",
            "message": "ç•¶å‰å­˜å„²çš„æ•¸æ“šçµæ§‹",
            "json_data": sample_send_data,
            "timestamp": datetime.now().isoformat(),
            "webhook_url": CONFIG['WEBHOOK_CONFIG']['n8n_webhook_url']
        }

    except Exception as e:
        logger.error(f"âŒ èª¿è©¦æ•¸æ“šç«¯é»éŒ¯èª¤: {str(e)}")
        return {
            "status": "error",
            "message": f"èª¿è©¦æ•¸æ“šå¤±æ•—: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }


@app.get("/health")
async def health_check():
    """ç³»çµ±å¥åº·æª¢æŸ¥ - å¢å¼·ç‰ˆæœ¬"""
    uptime = datetime.now() - system_stats["uptime_start"]

    # æ¸¬è©¦é»ƒé‡‘åƒ¹æ ¼ API
    gold_api_status = "healthy"
    try:
        import yfinance as yf
        test_ticker = yf.Ticker("GC=F")
        test_data = test_ticker.history(period="1d", interval="1d")
        if test_data.empty:
            gold_api_status = "degraded"
    except Exception:
        gold_api_status = "unhealthy"

    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "system": CONFIG['SYSTEM_INFO']['name'],
        "version": CONFIG['SYSTEM_INFO']['version'],
        "has_market_data": len(stored_data) > 0,
        "uptime": str(uptime).split('.')[0],
        "environment": os.getenv('ENVIRONMENT', 'development'),
        "stats": system_stats,
        "features": {
            "gold_price_api": gold_api_status,
            "market_analysis": "healthy",
            "mail_sender": "healthy",
            "real_time_updates": "healthy"
        },
        "services": {
            "yfinance": gold_api_status,
            "n8n_webhook": "unknown",
            "static_files": "healthy"
        }
    }


# è¼”åŠ©å‡½æ•¸
def get_sentiment_text(score: float) -> str:
    """æ ¹æ“šæƒ…æ„Ÿåˆ†æ•¸è¿”å›æ–‡å­—æè¿°"""
    if score > 80:
        return "æ¥µåº¦æ¨‚è§€"
    elif score > 60:
        return "æ¨‚è§€"
    elif score > 50:
        return "ä¸­æ€§åæ¨‚è§€"
    elif score >= 40:
        return "ä¸­æ€§"
    elif score > 30:
        return "ä¸­æ€§åæ‚²è§€"
    elif score > 20:
        return "æ‚²è§€"
    else:
        return "æ¥µåº¦æ‚²è§€"


def get_market_emoji(score: float) -> str:
    """æ ¹æ“šæƒ…æ„Ÿåˆ†æ•¸è¿”å›è¡¨æƒ…ç¬¦è™Ÿ"""
    if score > 80:
        return "ğŸš€ğŸ“ˆğŸ’š"
    elif score > 60:
        return "ğŸ“ˆğŸŸ¢ğŸ˜Š"
    elif score > 50:
        return "ğŸ“ŠğŸŸ¡ğŸ˜"
    elif score >= 40:
        return "â¡ï¸âšªğŸ˜‘"
    elif score > 30:
        return "ğŸ“ŠğŸŸ¡ğŸ˜"
    elif score > 20:
        return "ğŸ“‰ğŸ”´ğŸ˜Ÿ"
    else:
        return "ğŸ’¥ğŸ“‰ğŸ˜±"


# éŒ¯èª¤è™•ç†
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    logger.error(f"HTTPç•°å¸¸: {exc.status_code} - {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "status": "error",
            "message": exc.detail,
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url)
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"æœªè™•ç†çš„ç•°å¸¸: {str(exc)}")
    system_stats["errors"] += 1
    return JSONResponse(
        status_code=500,
        content={
            "status": "error",
            "message": "å…§éƒ¨æœå‹™å™¨éŒ¯èª¤",
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url)
        }
    )


def main():
    uvicorn.run(
        app,
        host=CONFIG['SERVER_CONFIG']['host'],
        port=CONFIG['SERVER_CONFIG']['port'],
        log_level="info",
        reload=CONFIG['SERVER_CONFIG'].get('debug', False)
    )


if __name__ == "__main__":
    main()